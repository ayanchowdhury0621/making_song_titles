{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import re\n",
    "from gensim.parsing.preprocessing import strip_punctuation, strip_non_alphanum\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Flatten, TimeDistributed, Dense, Dropout, Embedding, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Album</th>\n",
       "      <th>Date</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​thank u, next</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>2018-11-03</td>\n",
       "      <td>thought i'd end up with sean but he wasn't a m...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>7 rings</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>yeah breakfast at tiffany's and bottles of bub...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​God is a woman</td>\n",
       "      <td>Sweetener</td>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>you you love it how i move you you love it how...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>Side To Side</td>\n",
       "      <td>Dangerous Woman</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>ariana grande  nicki minaj i've been here all ...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​​no tears left to cry</td>\n",
       "      <td>Sweetener</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>right now i'm in a state of mind i wanna be in...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Artist                   Title            Album        Date  \\\n",
       "0  Ariana Grande          ​thank u, next    thank u, next  2018-11-03   \n",
       "1  Ariana Grande                 7 rings    thank u, next  2019-01-18   \n",
       "2  Ariana Grande         ​God is a woman        Sweetener  2018-07-13   \n",
       "3  Ariana Grande            Side To Side  Dangerous Woman  2016-05-20   \n",
       "4  Ariana Grande  ​​no tears left to cry        Sweetener  2018-04-20   \n",
       "\n",
       "                                               Lyric  Year  \n",
       "0  thought i'd end up with sean but he wasn't a m...  2018  \n",
       "1  yeah breakfast at tiffany's and bottles of bub...  2019  \n",
       "2  you you love it how i move you you love it how...  2018  \n",
       "3  ariana grande  nicki minaj i've been here all ...  2016  \n",
       "4  right now i'm in a state of mind i wanna be in...  2018  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import Kaggle lyrics data into csv\n",
    "df_songs = pd.read_csv('all_lyrics.csv', index_col=0)\n",
    "df_songs = df_songs.dropna(subset=['Title', 'Lyric'])\n",
    "df_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into x (lyrics) and corresponding y (titles)\n",
    "def split_x_y(df):\n",
    "    lyrics = []\n",
    "    titles = []\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        lyrics.append(row['Lyric'])\n",
    "        titles.append(row['Title'])\n",
    "    \n",
    "    return lyrics, titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process lyrics and titles consistenly\n",
    "def pre_process_lyrics_and_titles(lyrics: list, titles: list):\n",
    "    for idx in range(len(lyrics)):\n",
    "        song_lyrics = lyrics[idx]\n",
    "        song_lyrics = strip_punctuation(song_lyrics) # remove punctuation\n",
    "        song_lyrics = strip_non_alphanum(song_lyrics)\n",
    "        song_lyrics = song_lyrics.replace('\\u200b', '')\n",
    "        song_lyrics = song_lyrics.lower() # make all text lowercase\n",
    "        song_lyrics = word_tokenize(song_lyrics)\n",
    "        lyrics[idx] = ['<s>'] + song_lyrics + ['</s>']\n",
    "\n",
    "        title = titles[idx]\n",
    "        title = strip_punctuation(title) # remove punctuation\n",
    "        title = strip_non_alphanum(title)\n",
    "        title = title.replace('\\u200b', '') # remove punctuation\n",
    "        title = title.lower() # make all text lowercase \n",
    "        title = word_tokenize(title)\n",
    "        titles[idx] = ['<s>'] + title + ['</s>']\n",
    "        \n",
    "    return lyrics, titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics, titles = split_x_y(df_songs.head(2000))\n",
    "lyrics, titles = pre_process_lyrics_and_titles(lyrics, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word embeddings\n",
    "EMBEDDINGS_SIZE = 200\n",
    "\n",
    "def train_word_embeddings(lyrics, titles):\n",
    "    sg = 1\n",
    "    window = 5\n",
    "    vector_size = EMBEDDINGS_SIZE\n",
    "    min_count = 1\n",
    "    model_lyrics = Word2Vec(sentences=lyrics, size=vector_size, window=window, min_count=min_count, sg=sg)\n",
    "    model_lyrics.save(\"model_lyrics\")\n",
    "    model_lyrics.wv.save_word2vec_format('model_lyrics.txt', binary=False)\n",
    "\n",
    "    model_titles = Word2Vec(sentences=titles, size=vector_size, window=window, min_count=min_count, sg=sg)\n",
    "    model_titles.save(\"model_titles\")\n",
    "    model_titles.wv.save_word2vec_format('model_titles.txt', binary=False)\n",
    "    return model_lyrics, model_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lyrics, model_titles = train_word_embeddings(lyrics, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode data into integers\n",
    "\n",
    "def encode_data(lyrics, titles):\n",
    "    tokenizer_lyrics = Tokenizer()\n",
    "    tokenizer_titles = Tokenizer()\n",
    "    \n",
    "    # fit the tokenizer on your data\n",
    "    tokenizer_lyrics.fit_on_texts(lyrics)\n",
    "    tokenizer_titles.fit_on_texts(titles)\n",
    "    \n",
    "    # convert your data to sequences\n",
    "    lyrics_encoded = tokenizer_lyrics.texts_to_sequences(lyrics)\n",
    "    titles_encoded = tokenizer_titles.texts_to_sequences(titles)\n",
    "    \n",
    "    return lyrics_encoded, titles_encoded, tokenizer_lyrics, tokenizer_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_encoded, titles_encoded, tokenizer_lyrics, tokenizer_titles = encode_data(lyrics, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 1: RNN with LSTM --> using pretrained embeddings from Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in embeddings from folder\n",
    "\n",
    "def read_embeddings():\n",
    "    model_lyrics_loaded = KeyedVectors.load_word2vec_format(\"model_lyrics.txt\")\n",
    "    model_titles_loaded = KeyedVectors.load_word2vec_format(\"model_titles.txt\")\n",
    "\n",
    "    word_to_embedding_lyrics = {}\n",
    "    index_to_embedding_lyrics = {}\n",
    "    for word in model_lyrics_loaded.wv.vocab:\n",
    "        embedding = model_lyrics_loaded.wv[word]\n",
    "        word_to_embedding_lyrics[word] = embedding\n",
    "        index = tokenizer_lyrics.word_index[word]\n",
    "        index_to_embedding_lyrics[index] = embedding\n",
    "\n",
    "    word_to_embedding_titles = {}\n",
    "    index_to_embedding_titles = {}\n",
    "    for word in model_titles_loaded.wv.vocab:\n",
    "        embedding = model_titles_loaded.wv[word]\n",
    "        word_to_embedding_titles[word] = embedding\n",
    "        index = tokenizer_titles.word_index[word]\n",
    "        index_to_embedding_titles[index] = embedding\n",
    "        \n",
    "    return (model_lyrics_loaded, model_titles_loaded, word_to_embedding_lyrics, \n",
    "index_to_embedding_lyrics, word_to_embedding_titles, index_to_embedding_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ayan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n",
      "/Users/Ayan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/Ayan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/Users/Ayan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "embeddings = read_embeddings()\n",
    "model_lyrics_loaded = embeddings[0]\n",
    "model_titles_loaded = embeddings[1]\n",
    "word_to_embedding_lyrics = embeddings[2]\n",
    "index_to_embedding_lyrics = embeddings[3]\n",
    "word_to_embedding_titles = embeddings[4]\n",
    "index_to_embedding_titles = embeddings[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(lyrics_encoded, titles_encoded, index_to_embedding_lyrics, index_to_embedding_titles, batch_size):\n",
    "    while True:\n",
    "\n",
    "        # Loop over the batches\n",
    "        for idx in range(len(lyrics_encoded)):\n",
    "            start_idx = idx\n",
    "            if (idx+batch_size < len(lyrics_encoded)):   \n",
    "                end_idx = idx + batch_size\n",
    "            else: \n",
    "                end_idx = batch_size\n",
    "                batch_X_lyrics = lyrics_encoded[start_idx:end_idx]\n",
    "                batch_y = titles_encoded[start_idx:end_idx]\n",
    "                \n",
    "                start_idx = 0\n",
    "                end_idx = batch_size - (len(lyrics_encoded) - idx)\n",
    "                batch_X_lyrics += lyrics_encoded[start_idx:end_idx]\n",
    "                batch_y += titles_encoded[start_idx:end_idx]\n",
    "\n",
    "            # Get the current batch of encoded lyrics and titles\n",
    "            batch_X_lyrics = lyrics_encoded[start_idx:end_idx]\n",
    "            batch_y = titles_encoded[start_idx:end_idx]\n",
    "\n",
    "            # Calculate the maximum length of the sequences in the batch\n",
    "            max_seq_length = max(len(seq) for seq in batch_X_lyrics + batch_y)\n",
    "\n",
    "            # Pad the sequences to the maximum length\n",
    "            batch_X_lyrics = pad_sequences(batch_X_lyrics, maxlen=max_seq_length, padding='post')\n",
    "            batch_y = pad_sequences(batch_y, maxlen=max_seq_length, padding='post')\n",
    "            \n",
    "            # Create an array of shape (batch_size, sequence_length, embedding_dim) to hold the embeddings for the current batch of lyrics\n",
    "            batch_X_lyrics_emb = np.array([[\n",
    "                # if the index is in the index_to_embedding_lyrics dictionary, use its embedding\n",
    "                # otherwise, use a zero vector of the appropriate length\n",
    "                index_to_embedding_lyrics.get(idx, np.zeros(len(index_to_embedding_lyrics[1]))) for idx in seq\n",
    "            ] for seq in batch_X_lyrics])\n",
    "            \n",
    "            # Create an array of shape (batch_size, sequence_length, vocab_size) to hold the one-hot encodings for the current batch of titles\n",
    "            batch_y_onehot = to_categorical(batch_y, num_classes=len(index_to_embedding_titles))\n",
    "            \n",
    "            # Yield the current batch of embeddings for lyrics and titles\n",
    "            yield (batch_X_lyrics_emb, batch_y_onehot)\n",
    "            batch_X_lyrics_emb = []\n",
    "            batch_y_onehot = []\n",
    "            idx = end_idx # set back for next loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 793, 200)\n",
      "(32, 793, 1974)\n"
     ]
    }
   ],
   "source": [
    "#Examples\n",
    "#initialize data_generator\n",
    "num_sequences_per_batch = 32 # this is the batch size\n",
    "steps_per_epoch_lyrics = len(lyrics_encoded)//num_sequences_per_batch  # Number of batches per epoch\n",
    "train_generator_lyrics = data_generator(lyrics_encoded, titles_encoded, index_to_embedding_lyrics, index_to_embedding_titles, 32)\n",
    "\n",
    "sample=next(train_generator_lyrics) # this is how you get data out of generators\n",
    "print(sample[0].shape) \n",
    "print(sample[1].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(generator, index_to_embedding_lyrics, index_to_embedding_titles, batch_size=128, epochs=5, validation_split=0.2, dropout_rate=0.2, lstm_units=5):\n",
    "    # Split the data into training and validation sets\n",
    "    X, y = next(generator)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=validation_split, shuffle=False)\n",
    "    steps_per_epoch = math.ceil(len(X_train) / batch_size)\n",
    "\n",
    "    # Build the model\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units=lstm_units, return_sequences=True), input_shape=(None, len(index_to_embedding_lyrics[1]))))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(TimeDistributed(Dense(units=len(index_to_embedding_titles), activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, steps_per_epoch=steps_per_epoch, epochs=epochs, validation_data=(X_val, y_val), verbose=1)\n",
    "    loss, accuracy = model.evaluate(X_val, y_val, steps=steps_per_epoch, verbose=1)\n",
    "    print(\"Validation loss:\", loss)\n",
    "    print(\"Validation accuracy:\", accuracy)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running with lstm units:  5 \n",
      "running with dropout rate:  0.1 \n",
      "running with batch size:  32 \n",
      "running with epochs:  3\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, None, 10)         8240      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 10)          0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, None, 1974)       21714     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,954\n",
      "Trainable params: 29,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7e0f119f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7e0f119f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5905 - accuracy: 0.2828WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7dbd2c45f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7dbd2c45f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.5905 - accuracy: 0.2828 - val_loss: 7.5832 - val_accuracy: 0.3048\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5828 - accuracy: 0.3855 - val_loss: 7.5741 - val_accuracy: 0.3088\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5749 - accuracy: 0.3919 - val_loss: 7.5648 - val_accuracy: 0.3111\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 7.5648 - accuracy: 0.3111\n",
      "Validation loss: 7.5647711753845215\n",
      "Validation accuracy: 0.3111151158809662\n",
      "<keras.engine.sequential.Sequential object at 0x7f7de0ffca10>\n",
      "running with lstm units:  5 \n",
      "running with dropout rate:  0.1 \n",
      "running with batch size:  32 \n",
      "running with epochs:  7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_1 (Bidirectio  (None, None, 10)         8240      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 10)          0         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, None, 1974)       21714     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,954\n",
      "Trainable params: 29,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/7\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7d3027b4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7d3027b4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5699 - accuracy: 0.3254WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7d326c1170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7d326c1170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.5699 - accuracy: 0.3254 - val_loss: 7.5547 - val_accuracy: 0.3149\n",
      "Epoch 2/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5583 - accuracy: 0.3982 - val_loss: 7.5416 - val_accuracy: 0.3194\n",
      "Epoch 3/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5464 - accuracy: 0.4051 - val_loss: 7.5285 - val_accuracy: 0.3448\n",
      "Epoch 4/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5348 - accuracy: 0.4430 - val_loss: 7.5153 - val_accuracy: 0.6981\n",
      "Epoch 5/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5229 - accuracy: 0.6459 - val_loss: 7.5022 - val_accuracy: 0.9643\n",
      "Epoch 6/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5109 - accuracy: 0.8729 - val_loss: 7.4892 - val_accuracy: 0.9942\n",
      "Epoch 7/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.4993 - accuracy: 0.9593 - val_loss: 7.4764 - val_accuracy: 0.9951\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 7.4764 - accuracy: 0.9951\n",
      "Validation loss: 7.4764485359191895\n",
      "Validation accuracy: 0.995136022567749\n",
      "<keras.engine.sequential.Sequential object at 0x7f7dbd823510>\n",
      "running with lstm units:  5 \n",
      "running with dropout rate:  0.2 \n",
      "running with batch size:  32 \n",
      "running with epochs:  3\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (None, None, 10)         8240      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 10)          0         \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, None, 1974)       21714     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,954\n",
      "Trainable params: 29,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7d302b9290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7d302b9290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.6046 - accuracy: 0.2442WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7d32a18cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7d32a18cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.6046 - accuracy: 0.2442 - val_loss: 7.5977 - val_accuracy: 0.2841\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5955 - accuracy: 0.3691 - val_loss: 7.5880 - val_accuracy: 0.2938\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5871 - accuracy: 0.3702 - val_loss: 7.5791 - val_accuracy: 0.3034\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 7.5791 - accuracy: 0.3034\n",
      "Validation loss: 7.5790510177612305\n",
      "Validation accuracy: 0.30336877703666687\n",
      "<keras.engine.sequential.Sequential object at 0x7f7d300dbd90>\n",
      "running with lstm units:  5 \n",
      "running with dropout rate:  0.2 \n",
      "running with batch size:  32 \n",
      "running with epochs:  7\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_3 (Bidirectio  (None, None, 10)         8240      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, None, 10)          0         \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, None, 1974)       21714     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,954\n",
      "Trainable params: 29,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/7\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7d302140e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7d302140e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5802 - accuracy: 0.2028WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7ce4650ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7ce4650ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.5802 - accuracy: 0.2028 - val_loss: 7.5691 - val_accuracy: 0.2209\n",
      "Epoch 2/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5729 - accuracy: 0.3384 - val_loss: 7.5601 - val_accuracy: 0.2293\n",
      "Epoch 3/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5653 - accuracy: 0.3490 - val_loss: 7.5506 - val_accuracy: 0.2340\n",
      "Epoch 4/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5572 - accuracy: 0.3539 - val_loss: 7.5406 - val_accuracy: 0.2376\n",
      "Epoch 5/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5487 - accuracy: 0.3625 - val_loss: 7.5301 - val_accuracy: 0.2409\n",
      "Epoch 6/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5396 - accuracy: 0.3689 - val_loss: 7.5191 - val_accuracy: 0.2479\n",
      "Epoch 7/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5305 - accuracy: 0.3927 - val_loss: 7.5075 - val_accuracy: 0.2673\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 7.5075 - accuracy: 0.2673\n",
      "Validation loss: 7.507519721984863\n",
      "Validation accuracy: 0.26733922958374023\n",
      "<keras.engine.sequential.Sequential object at 0x7f7d302090d0>\n",
      "running with lstm units:  5 \n",
      "running with dropout rate:  0.25 \n",
      "running with batch size:  32 \n",
      "running with epochs:  3\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_4 (Bidirectio  (None, None, 10)         8240      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, None, 10)          0         \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, None, 1974)       21714     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,954\n",
      "Trainable params: 29,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7d0292d560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7d0292d560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5938 - accuracy: 0.3693WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7e0ece8950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7e0ece8950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.5938 - accuracy: 0.3693 - val_loss: 7.5881 - val_accuracy: 0.2855\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5872 - accuracy: 0.3422 - val_loss: 7.5806 - val_accuracy: 0.2902\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5808 - accuracy: 0.3452 - val_loss: 7.5731 - val_accuracy: 0.2960\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 7.5731 - accuracy: 0.2960\n",
      "Validation loss: 7.573086261749268\n",
      "Validation accuracy: 0.2959827184677124\n",
      "<keras.engine.sequential.Sequential object at 0x7f7ce3d5b050>\n",
      "running with lstm units:  5 \n",
      "running with dropout rate:  0.25 \n",
      "running with batch size:  32 \n",
      "running with epochs:  7\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_5 (Bidirectio  (None, None, 10)         8240      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, None, 10)          0         \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, None, 1974)       21714     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,954\n",
      "Trainable params: 29,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/7\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7dbcbfa950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7dbcbfa950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5932 - accuracy: 0.3787WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7dbb6599e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7dbb6599e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.5932 - accuracy: 0.3787 - val_loss: 7.5850 - val_accuracy: 0.3745\n",
      "Epoch 2/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5837 - accuracy: 0.4135 - val_loss: 7.5756 - val_accuracy: 0.3770\n",
      "Epoch 3/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5749 - accuracy: 0.4161 - val_loss: 7.5667 - val_accuracy: 0.3796\n",
      "Epoch 4/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5665 - accuracy: 0.4199 - val_loss: 7.5577 - val_accuracy: 0.3864\n",
      "Epoch 5/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5579 - accuracy: 0.4327 - val_loss: 7.5487 - val_accuracy: 0.4624\n",
      "Epoch 6/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5494 - accuracy: 0.4727 - val_loss: 7.5395 - val_accuracy: 0.7024\n",
      "Epoch 7/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5406 - accuracy: 0.5662 - val_loss: 7.5299 - val_accuracy: 0.8658\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 7.5299 - accuracy: 0.8658\n",
      "Validation loss: 7.529874324798584\n",
      "Validation accuracy: 0.8657899498939514\n",
      "<keras.engine.sequential.Sequential object at 0x7f7d30227190>\n",
      "running with lstm units:  7 \n",
      "running with dropout rate:  0.1 \n",
      "running with batch size:  32 \n",
      "running with epochs:  3\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_6 (Bidirectio  (None, None, 14)         11648     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, None, 14)          0         \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, None, 1974)       29610     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,258\n",
      "Trainable params: 41,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7dbcb26a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7dbcb26a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5884 - accuracy: 0.3145WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7ce1698170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7ce1698170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.5884 - accuracy: 0.3145 - val_loss: 7.5793 - val_accuracy: 0.4931\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5770 - accuracy: 0.3810 - val_loss: 7.5701 - val_accuracy: 0.5028\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5658 - accuracy: 0.3884 - val_loss: 7.5609 - val_accuracy: 0.5120\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 7.5609 - accuracy: 0.5120\n",
      "Validation loss: 7.560946941375732\n",
      "Validation accuracy: 0.5119798183441162\n",
      "<keras.engine.sequential.Sequential object at 0x7f7dbd495b10>\n",
      "running with lstm units:  7 \n",
      "running with dropout rate:  0.1 \n",
      "running with batch size:  32 \n",
      "running with epochs:  7\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_7 (Bidirectio  (None, None, 14)         11648     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, None, 14)          0         \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, None, 1974)       29610     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,258\n",
      "Trainable params: 41,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/7\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7ce3aca320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7ce3aca320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5581 - accuracy: 0.3169WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7d32380440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7d32380440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.5581 - accuracy: 0.3169 - val_loss: 7.5564 - val_accuracy: 0.6067\n",
      "Epoch 2/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5463 - accuracy: 0.4544 - val_loss: 7.5463 - val_accuracy: 0.8173\n",
      "Epoch 3/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5338 - accuracy: 0.6578 - val_loss: 7.5353 - val_accuracy: 0.9492\n",
      "Epoch 4/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5200 - accuracy: 0.8481 - val_loss: 7.5236 - val_accuracy: 0.9737\n",
      "Epoch 5/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5051 - accuracy: 0.9457 - val_loss: 7.5111 - val_accuracy: 0.9784\n",
      "Epoch 6/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.4896 - accuracy: 0.9824 - val_loss: 7.4980 - val_accuracy: 0.9791\n",
      "Epoch 7/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.4730 - accuracy: 0.9924 - val_loss: 7.4843 - val_accuracy: 0.9809\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 7.4843 - accuracy: 0.9809\n",
      "Validation loss: 7.484303951263428\n",
      "Validation accuracy: 0.9809043407440186\n",
      "<keras.engine.sequential.Sequential object at 0x7f7ce3ab8690>\n",
      "running with lstm units:  7 \n",
      "running with dropout rate:  0.2 \n",
      "running with batch size:  32 \n",
      "running with epochs:  3\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_8 (Bidirectio  (None, None, 14)         11648     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, None, 14)          0         \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, None, 1974)       29610     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,258\n",
      "Trainable params: 41,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7dbcc3f440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7dbcc3f440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5832 - accuracy: 0.3174WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7ce5c315f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7ce5c315f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 5s 5s/step - loss: 7.5832 - accuracy: 0.3174 - val_loss: 7.5718 - val_accuracy: 0.4914\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5684 - accuracy: 0.3727 - val_loss: 7.5597 - val_accuracy: 0.4970\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5539 - accuracy: 0.3790 - val_loss: 7.5475 - val_accuracy: 0.5060\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 7.5475 - accuracy: 0.5060\n",
      "Validation loss: 7.5474724769592285\n",
      "Validation accuracy: 0.5060349702835083\n",
      "<keras.engine.sequential.Sequential object at 0x7f7cdf989ed0>\n",
      "running with lstm units:  7 \n",
      "running with dropout rate:  0.2 \n",
      "running with batch size:  32 \n",
      "running with epochs:  7\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_9 (Bidirectio  (None, None, 14)         11648     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, None, 14)          0         \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, None, 1974)       29610     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,258\n",
      "Trainable params: 41,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/7\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7d326d7ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7d326d7ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5944 - accuracy: 0.3275WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7dbcb19f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7dbcb19f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.5944 - accuracy: 0.3275 - val_loss: 7.5830 - val_accuracy: 0.5421\n",
      "Epoch 2/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5834 - accuracy: 0.3794 - val_loss: 7.5747 - val_accuracy: 0.5453\n",
      "Epoch 3/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5725 - accuracy: 0.3825 - val_loss: 7.5666 - val_accuracy: 0.5476\n",
      "Epoch 4/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5621 - accuracy: 0.3856 - val_loss: 7.5586 - val_accuracy: 0.5502\n",
      "Epoch 5/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5516 - accuracy: 0.3988 - val_loss: 7.5506 - val_accuracy: 0.5858\n",
      "Epoch 6/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5412 - accuracy: 0.4602 - val_loss: 7.5425 - val_accuracy: 0.8060\n",
      "Epoch 7/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5310 - accuracy: 0.5971 - val_loss: 7.5344 - val_accuracy: 0.9526\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 7.5344 - accuracy: 0.9526\n",
      "Validation loss: 7.534426689147949\n",
      "Validation accuracy: 0.9526211619377136\n",
      "<keras.engine.sequential.Sequential object at 0x7f7dbd406ed0>\n",
      "running with lstm units:  7 \n",
      "running with dropout rate:  0.25 \n",
      "running with batch size:  32 \n",
      "running with epochs:  3\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_10 (Bidirecti  (None, None, 14)         11648     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, None, 14)          0         \n",
      "                                                                 \n",
      " time_distributed_10 (TimeDi  (None, None, 1974)       29610     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,258\n",
      "Trainable params: 41,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7ce40a3dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7ce40a3dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5830 - accuracy: 0.3094WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7d326d7b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7d326d7b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.5830 - accuracy: 0.3094 - val_loss: 7.5752 - val_accuracy: 0.5599\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5710 - accuracy: 0.3552 - val_loss: 7.5665 - val_accuracy: 0.5633\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5593 - accuracy: 0.3609 - val_loss: 7.5579 - val_accuracy: 0.5675\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 7.5579 - accuracy: 0.5675\n",
      "Validation loss: 7.557888031005859\n",
      "Validation accuracy: 0.5674653053283691\n",
      "<keras.engine.sequential.Sequential object at 0x7f7d3037f5d0>\n",
      "running with lstm units:  7 \n",
      "running with dropout rate:  0.25 \n",
      "running with batch size:  32 \n",
      "running with epochs:  7\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_11 (Bidirecti  (None, None, 14)         11648     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, None, 14)          0         \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, None, 1974)       29610     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,258\n",
      "Trainable params: 41,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/7\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7ce20fde60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7ce20fde60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5718 - accuracy: 0.2764WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7d30242f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7d30242f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.5718 - accuracy: 0.2764 - val_loss: 7.5691 - val_accuracy: 0.5657\n",
      "Epoch 2/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5619 - accuracy: 0.3566 - val_loss: 7.5616 - val_accuracy: 0.6062\n",
      "Epoch 3/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5518 - accuracy: 0.4008 - val_loss: 7.5539 - val_accuracy: 0.8033\n",
      "Epoch 4/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5417 - accuracy: 0.5310 - val_loss: 7.5459 - val_accuracy: 0.9362\n",
      "Epoch 5/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5310 - accuracy: 0.7068 - val_loss: 7.5375 - val_accuracy: 0.9764\n",
      "Epoch 6/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5195 - accuracy: 0.8374 - val_loss: 7.5286 - val_accuracy: 0.9876\n",
      "Epoch 7/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5074 - accuracy: 0.9130 - val_loss: 7.5193 - val_accuracy: 0.9928\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 7.5193 - accuracy: 0.9928\n",
      "Validation loss: 7.5192646980285645\n",
      "Validation accuracy: 0.9927940964698792\n",
      "<keras.engine.sequential.Sequential object at 0x7f7ce45ef5d0>\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning \n",
    "\n",
    "lstm_units = [5, 7]\n",
    "dropout_rate = [0.1, 0.2, 0.25]\n",
    "batch_size = [32]\n",
    "epochs = [3, 7]\n",
    "\n",
    "train_test_generator_split = 0.7\n",
    "\n",
    "steps_per_epoch = len(lyrics_encoded) // num_sequences_per_batch\n",
    "generator_train = data_generator(lyrics_encoded[:round(len(lyrics_encoded) * train_test_generator_split)], titles_encoded[:round(len(titles_encoded) * train_test_generator_split)], index_to_embedding_lyrics, index_to_embedding_titles, 32)\n",
    "for units in lstm_units:\n",
    "    for rate in dropout_rate:\n",
    "        for size in batch_size:\n",
    "            for epoch in epochs:\n",
    "                print(\"running with lstm units: \", units, \"\\nrunning with dropout rate: \", rate, \"\\nrunning with batch size: \", size, \"\\nrunning with epochs: \", epoch)\n",
    "                val_accuracy = train_model(generator_train, index_to_embedding_lyrics, index_to_embedding_titles, batch_size=size, epochs=epoch, dropout_rate=rate, lstm_units=units)\n",
    "                print(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_12 (Bidirecti  (None, None, 10)         8240      \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, None, 10)          0         \n",
      "                                                                 \n",
      " time_distributed_12 (TimeDi  (None, None, 1974)       21714     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,954\n",
      "Trainable params: 29,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/7\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7ce2844b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7ce2844b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5960 - accuracy: 0.3303WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7ce0152170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7ce0152170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.5960 - accuracy: 0.3303 - val_loss: 7.5868 - val_accuracy: 0.3099\n",
      "Epoch 2/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5871 - accuracy: 0.3932 - val_loss: 7.5769 - val_accuracy: 0.3127\n",
      "Epoch 3/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5783 - accuracy: 0.3960 - val_loss: 7.5672 - val_accuracy: 0.3144\n",
      "Epoch 4/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5694 - accuracy: 0.3980 - val_loss: 7.5575 - val_accuracy: 0.3167\n",
      "Epoch 5/7\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5609 - accuracy: 0.3996 - val_loss: 7.5478 - val_accuracy: 0.3194\n",
      "Epoch 6/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5521 - accuracy: 0.4022 - val_loss: 7.5379 - val_accuracy: 0.3326\n",
      "Epoch 7/7\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5431 - accuracy: 0.4111 - val_loss: 7.5278 - val_accuracy: 0.4107\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 7.5278 - accuracy: 0.4107\n",
      "Validation loss: 7.5278096199035645\n",
      "Validation accuracy: 0.4107367992401123\n"
     ]
    }
   ],
   "source": [
    "train_test_generator_split = 0.7\n",
    "# create data generator with 70% of the data for training\n",
    "train_generator = data_generator(lyrics_encoded[:round(len(lyrics_encoded) * train_test_generator_split)], titles_encoded[:round(len(titles_encoded) * train_test_generator_split)], index_to_embedding_lyrics, index_to_embedding_titles, 32)\n",
    "# create data generator with 30% of the data for testing\n",
    "test_generator = data_generator(lyrics_encoded[round(len(lyrics_encoded) * train_test_generator_split):], titles_encoded[round(len(titles_encoded) * train_test_generator_split):], index_to_embedding_lyrics, index_to_embedding_titles, 32)\n",
    "# train best model on the best hyperparameters\n",
    "best_model = train_model(train_generator, index_to_embedding_lyrics, index_to_embedding_titles, batch_size=64, epochs=7, dropout_rate=0.2, lstm_units=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_one_hot_vectors_to_words(one_hot_vectors, tokenizer_title):\n",
    "    encoding_list = []\n",
    "    title_list = []\n",
    "    len_title = 0\n",
    "    reverse_word_map = dict(map(reversed, tokenizer_title.word_index.items()))\n",
    "    for i in range(len(one_hot_vectors)):\n",
    "        if (one_hot_vectors[i][0] == 1): # remove all zero vectors from padded y_test input\n",
    "            continue\n",
    "        else:\n",
    "            encoding_list.append(list(one_hot_vectors[i]).index(1)) # add index of title (index where 1 is in encoding)\n",
    "    \n",
    "    for encoding in encoding_list:\n",
    "        title_list.append(reverse_word_map[encoding]) # get word from index\n",
    "     \n",
    "    len_title = len(title_list)\n",
    "    \n",
    "    actual_title = ' '.join(title_list)\n",
    "    \n",
    "    return actual_title, len_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_title(model, test_generator, tokenizer):\n",
    "\n",
    "    X_test, y_test = next(test_generator)\n",
    "    reverse_word_map = dict(map(reversed, tokenizer.word_index.items())) # map index to word\n",
    "    all_predicted_titles = []\n",
    "    all_actual_titles = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        current_song = np.expand_dims(X_test[i], axis=0)\n",
    "        actual_title, len_actual_title = convert_one_hot_vectors_to_words(y_test[i], tokenizer)\n",
    "\n",
    "        predictions = model.predict(current_song)\n",
    "\n",
    "        # Get the most likely word for each time step in the output sequence\n",
    "        predicted_indices = np.argmax(predictions, axis=1)[0]\n",
    "        \n",
    "\n",
    "        # Convert the predicted indices to words\n",
    "        predicted_words = [reverse_word_map[idx] for idx in predicted_indices if idx != 0][0:len_actual_title]\n",
    "\n",
    "        # Join the predicted words to form the title\n",
    "        title = ' '.join(predicted_words)\n",
    "        \n",
    "        print(\"Actual title: \", actual_title)\n",
    "        print(\"Predicted title: \", title)\n",
    "        \n",
    "        all_predicted_titles.append(title)\n",
    "        all_actual_titles.append(actual_title)\n",
    "        \n",
    "    return all_actual_titles, all_predicted_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Actual title:  <s> bitter sweet symphony </s>\n",
      "Predicted title:  why <s> hold why favor\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Actual title:  <s> o fly on extended version </s>\n",
      "Predicted title:  is chinese back make never like freestyle\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Actual title:  <s> a head full of dreams live in buenos aires </s>\n",
      "Predicted title:  partition chinese bout first gone touch live chinese 11 partition vida\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Actual title:  <s> now my feet won t touch the ground </s>\n",
      "Predicted title:  man chinese the mix song it life chinese chinese interlude\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Actual title:  <s> moses </s>\n",
      "Predicted title:  heart music only\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Actual title:  <s> rainy day </s>\n",
      "Predicted title:  life chinese do life\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Actual title:  <s> moving to mars </s>\n",
      "Predicted title:  head all lost all check\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Actual title:  <s> careful where you stand </s>\n",
      "Predicted title:  at chinese girls ocean edit single\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Actual title:  <s> i ran away </s>\n",
      "Predicted title:  yellow chinese problem butterfly third\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Actual title:  <s> in the sun </s>\n",
      "Predicted title:  clean chinese need room copycat\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Actual title:  <s> midnight kygo remix </s>\n",
      "Predicted title:  and chinese you is all\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Actual title:  <s> bigger stronger </s>\n",
      "Predicted title:  experience live music we\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Actual title:  <s> help is round the corner </s>\n",
      "Predicted title:  t chinese interlude new sweet put cover\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Actual title:  <s> brothers sisters </s>\n",
      "Predicted title:  not yourself go check\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Actual title:  <s> animals </s>\n",
      "Predicted title:  one chinese vu\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Actual title:  <s> talk leaked version </s>\n",
      "Predicted title:  myself chinese bellyache myself girl\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Actual title:  <s> things i don t understand </s>\n",
      "Predicted title:  radio chinese new tour pt new beyoncé\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Actual title:  <s> crests of waves </s>\n",
      "Predicted title:  time remix third remix sun\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Actual title:  <s> such a rush </s>\n",
      "Predicted title:  tears chinese white new fire\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Actual title:  <s> 2000 miles </s>\n",
      "Predicted title:  out chinese beautiful cry\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Actual title:  <s> 1 36 </s>\n",
      "Predicted title:  how chinese over head\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Actual title:  <s> believe in love </s>\n",
      "Predicted title:  interlude chinese now no you\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Actual title:  <s> easy to please </s>\n",
      "Predicted title:  the chinese club homecoming with\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Actual title:  <s> one i love </s>\n",
      "Predicted title:  with chinese of it intro\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Actual title:  <s> o reprise </s>\n",
      "Predicted title:  remix chinese the demo\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Actual title:  <s> amor argentina live in buenos aires </s>\n",
      "Predicted title:  single chinese better crazy la man girls and\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Actual title:  <s> wotw potp live in jordan version </s>\n",
      "Predicted title:  is chinese 2 love 2 like from chinese\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Actual title:  <s> super bowl 50 halftime show </s>\n",
      "Predicted title:  s chinese the to s remix it\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Actual title:  <s> imagine </s>\n",
      "Predicted title:  talk chinese edit\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Actual title:  <s> lethal drug </s>\n",
      "Predicted title:  part chinese sun blue\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Actual title:  <s> colour spectrum live in buenos aires </s>\n",
      "Predicted title:  pt chinese the buenos baby girl baby chinese\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Actual title:  <s> the world turned upside down </s>\n",
      "Predicted title:  just chinese alarm life to la more\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['<s> bitter sweet symphony </s>',\n",
       "  '<s> o fly on extended version </s>',\n",
       "  '<s> a head full of dreams live in buenos aires </s>',\n",
       "  '<s> now my feet won t touch the ground </s>',\n",
       "  '<s> moses </s>',\n",
       "  '<s> rainy day </s>',\n",
       "  '<s> moving to mars </s>',\n",
       "  '<s> careful where you stand </s>',\n",
       "  '<s> i ran away </s>',\n",
       "  '<s> in the sun </s>',\n",
       "  '<s> midnight kygo remix </s>',\n",
       "  '<s> bigger stronger </s>',\n",
       "  '<s> help is round the corner </s>',\n",
       "  '<s> brothers sisters </s>',\n",
       "  '<s> animals </s>',\n",
       "  '<s> talk leaked version </s>',\n",
       "  '<s> things i don t understand </s>',\n",
       "  '<s> crests of waves </s>',\n",
       "  '<s> such a rush </s>',\n",
       "  '<s> 2000 miles </s>',\n",
       "  '<s> 1 36 </s>',\n",
       "  '<s> believe in love </s>',\n",
       "  '<s> easy to please </s>',\n",
       "  '<s> one i love </s>',\n",
       "  '<s> o reprise </s>',\n",
       "  '<s> amor argentina live in buenos aires </s>',\n",
       "  '<s> wotw potp live in jordan version </s>',\n",
       "  '<s> super bowl 50 halftime show </s>',\n",
       "  '<s> imagine </s>',\n",
       "  '<s> lethal drug </s>',\n",
       "  '<s> colour spectrum live in buenos aires </s>',\n",
       "  '<s> the world turned upside down </s>'],\n",
       " ['why <s> hold why favor',\n",
       "  'is chinese back make never like freestyle',\n",
       "  'partition chinese bout first gone touch live chinese 11 partition vida',\n",
       "  'man chinese the mix song it life chinese chinese interlude',\n",
       "  'heart music only',\n",
       "  'life chinese do life',\n",
       "  'head all lost all check',\n",
       "  'at chinese girls ocean edit single',\n",
       "  'yellow chinese problem butterfly third',\n",
       "  'clean chinese need room copycat',\n",
       "  'and chinese you is all',\n",
       "  'experience live music we',\n",
       "  't chinese interlude new sweet put cover',\n",
       "  'not yourself go check',\n",
       "  'one chinese vu',\n",
       "  'myself chinese bellyache myself girl',\n",
       "  'radio chinese new tour pt new beyoncé',\n",
       "  'time remix third remix sun',\n",
       "  'tears chinese white new fire',\n",
       "  'out chinese beautiful cry',\n",
       "  'how chinese over head',\n",
       "  'interlude chinese now no you',\n",
       "  'the chinese club homecoming with',\n",
       "  'with chinese of it intro',\n",
       "  'remix chinese the demo',\n",
       "  'single chinese better crazy la man girls and',\n",
       "  'is chinese 2 love 2 like from chinese',\n",
       "  's chinese the to s remix it',\n",
       "  'talk chinese edit',\n",
       "  'part chinese sun blue',\n",
       "  'pt chinese the buenos baby girl baby chinese',\n",
       "  'just chinese alarm life to la more'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_title(best_model, test_generator, tokenizer_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 2: RNN with Embedding Layer + Generation w/Shannon's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad each sequence of lyrics to a length of 130\n",
    "batch_X_lyrics = pad_sequences(lyrics_encoded, maxlen=130, padding='post')\n",
    "# pad each sequence of titles to a length of 130\n",
    "batch_y = pad_sequences(titles_encoded, maxlen=130, padding='post')\n",
    "# create one hot vectors for each title for RNN processing, num_classes adds 1 to account for padding token\n",
    "batch_y_onehot = to_categorical(batch_y, num_classes=len(tokenizer_titles.word_index)+1)\n",
    "# get total number of lyrics and titles for input shapes for the RNN\n",
    "total_words_lyrics = len(tokenizer_lyrics.word_index) + 1\n",
    "total_words_titles = len(tokenizer_titles.word_index) + 1\n",
    "\n",
    "# split data into training and testing after creating batches (using train_test_split from Model 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(batch_X_lyrics, batch_y_onehot, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 200)         6889800   \n",
      "                                                                 \n",
      " bidirectional_16 (Bidirecti  (None, None, 10)         8240      \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " time_distributed_16 (TimeDi  (None, None, 1975)       21725     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,919,765\n",
      "Trainable params: 6,919,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7b44ae0ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7b44ae0ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13/13 [==============================] - 46s 3s/step - loss: 7.5659 - accuracy: 0.6901\n",
      "Epoch 2/3\n",
      "13/13 [==============================] - 32s 2s/step - loss: 7.4642 - accuracy: 0.9579\n",
      "Epoch 3/3\n",
      "13/13 [==============================] - 26s 2s/step - loss: 7.2223 - accuracy: 0.9580\n"
     ]
    }
   ],
   "source": [
    "def train_model_two(train_padseq, y_train, total_words_lyrics, total_words_titles, maxlen):\n",
    "    # baseline model using embedding layers and simpleRNN\n",
    "    model = Sequential()\n",
    "    # embedding layer --> compressing input shape of total number of lyrics to dense vectors of length 200\n",
    "    model.add(Embedding(total_words_lyrics, 200))\n",
    "    # LSTM layer\n",
    "    model.add(Bidirectional(LSTM(5, dropout=0.5, recurrent_dropout=0.50, activation='tanh', return_sequences=True)))\n",
    "    # Dense output layer of output shape of total number of titles\n",
    "    model.add(TimeDistributed(Dense(total_words_titles, activation='softmax')))\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    # compile model using optimizer, loss function, metrics\n",
    "    model.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "            )\n",
    "    \n",
    "    # fit model to the data\n",
    "    history = model.fit(train_padseq, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=3\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_two = train_model_two(X_train, y_train, total_words_lyrics, total_words_titles, 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f7d029d5290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f7d029d5290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 1s 763ms/step\n",
      "Actual title:  <s> step on over </s>\n",
      "Predicted title:  <s> invented thrill nala</s>\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Actual title:  <s> love is everything </s>\n",
      "Predicted title:  <s> daylight sydney night</s>\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Actual title:  <s> stigma </s>\n",
      "Predicted title:  <s> november</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> awake </s>\n",
      "Predicted title:  <s> freestyle</s>\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Actual title:  <s> new york live </s>\n",
      "Predicted title:  <s> rebel bigger 轉</s>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Actual title:  <s> share </s>\n",
      "Predicted title:  <s> 잠시</s>\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Actual title:  <s> animals </s>\n",
      "Predicted title:  <s> bonds</s>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Actual title:  <s> yellow live in buenos aires </s>\n",
      "Predicted title:  <s> edit new summer 1999 hills</s>\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Actual title:  <s> summertime </s>\n",
      "Predicted title:  <s> yourself</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> marvin gaye remix </s>\n",
      "Predicted title:  <s> motto lust moses</s>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Actual title:  <s> thank u next video version </s>\n",
      "Predicted title:  <s> black 학교의눈물 d about settle</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> 이불킥 blanket kick embarrassed </s>\n",
      "Predicted title:  <s> florida own under da</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> dance for you </s>\n",
      "Predicted title:  <s> gay bands cream</s>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Actual title:  <s> ghostin </s>\n",
      "Predicted title:  <s> strawberry</s>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Actual title:  <s> fire japanese ver </s>\n",
      "Predicted title:  <s> light control days</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> from florida with love </s>\n",
      "Predicted title:  <s> intoxicated around yoncé ballad</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> hostage akay remix </s>\n",
      "Predicted title:  <s> hide that f</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> sweetener world tour costumes </s>\n",
      "Predicted title:  <s> dance left boy need</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> clocks </s>\n",
      "Predicted title:  <s> siembab</s>\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Actual title:  <s> go out tonight </s>\n",
      "Predicted title:  <s> money more street</s>\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Actual title:  <s> we are bulletproof pt 2 </s>\n",
      "Predicted title:  <s> wizard ペップセ show theatre pain</s>\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Actual title:  <s> boy with luv japanese ver </s>\n",
      "Predicted title:  <s> as bria 11 dollar critiquing</s>\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Actual title:  <s> when i need a friend </s>\n",
      "Predicted title:  <s> cred catalyst 6pm rather jaded</s>\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "Actual title:  <s> baby you re the only man </s>\n",
      "Predicted title:  <s> tú mind èkó goode stand 꺼줄래</s>\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "Actual title:  <s> crazy in love homecoming live </s>\n",
      "Predicted title:  <s> madonna c into cred coluccio</s>\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Actual title:  <s> take you down </s>\n",
      "Predicted title:  <s> bangtan florida kevorkian</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> dynamite edm remix </s>\n",
      "Predicted title:  <s> seoul faded sex</s>\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Actual title:  <s> everytime live </s>\n",
      "Predicted title:  <s> logic donk</s>\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Actual title:  <s> intro speak my mind </s>\n",
      "Predicted title:  <s> terjemahan city road jochen</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> two birds one stone </s>\n",
      "Predicted title:  <s> fantasy 흔한 nonstop answer</s>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Actual title:  <s> idontwannabeyouanymore </s>\n",
      "Predicted title:  <s> off</s>\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Actual title:  <s> pianist hands </s>\n",
      "Predicted title:  <s> seeb 힙합성애자</s>\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Actual title:  <s> them changes bbc radio 1 live lounge </s>\n",
      "Predicted title:  <s> west trivia all xo press 起 ode</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> brand new remix </s>\n",
      "Predicted title:  <s> first salto sun</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> 34 35 remix clean </s>\n",
      "Predicted title:  <s> 고엽 módl eilish giorgio</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> you don t love me no no no live </s>\n",
      "Predicted title:  <s> missin resentment ve violet 100 rihanna maurice summertime 40</s>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Actual title:  <s> move your body </s>\n",
      "Predicted title:  <s> elijah mad 18th</s>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Actual title:  <s> one last time dwt version </s>\n",
      "Predicted title:  <s> dynamite begin gon hands head</s>\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Actual title:  <s> bellyache devault remix </s>\n",
      "Predicted title:  <s> fight あの場所で best</s>\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Actual title:  <s> baby boy </s>\n",
      "Predicted title:  <s> dead scared</s>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Actual title:  <s> sliding </s>\n",
      "Predicted title:  <s> shot</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> loveless </s>\n",
      "Predicted title:  <s> ad</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> bug a boo roll call interlude homecoming live </s>\n",
      "Predicted title:  <s> thrill afraid barry tribute lethal major roc scientist</s>\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Actual title:  <s> introduction youth </s>\n",
      "Predicted title:  <s> boyz patient</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> daddy lessons </s>\n",
      "Predicted title:  <s> 1xtra sidney</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> sex tonight </s>\n",
      "Predicted title:  <s> teach quarantine</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> copycat live from the hi hat </s>\n",
      "Predicted title:  <s> touch this grave looks 92nd hook</s>\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Actual title:  <s> change </s>\n",
      "Predicted title:  <s> successful</s>\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "Actual title:  <s> midnight kygo remix </s>\n",
      "Predicted title:  <s> not 작은 guess</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> my side </s>\n",
      "Predicted title:  <s> valen 좋은</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> invented sex </s>\n",
      "Predicted title:  <s> grown topic</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> wit it this christmas </s>\n",
      "Predicted title:  <s> ligera haunted 땀 tough</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> on my way </s>\n",
      "Predicted title:  <s> youth at eres</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> standing on the sun remix </s>\n",
      "Predicted title:  <s> y amor eva morgan danger</s>\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Actual title:  <s> my boy troyboi remix </s>\n",
      "Predicted title:  <s> presentation 2010 bulletproof orphans</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> lord knows </s>\n",
      "Predicted title:  <s> settle gon</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> magic live in buenos aires </s>\n",
      "Predicted title:  <s> west slow 작은 euphoria bodak</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> boy </s>\n",
      "Predicted title:  <s> 크리스마스</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> instagram models </s>\n",
      "Predicted title:  <s> voice know</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> hard to say goodbye </s>\n",
      "Predicted title:  <s> bottom 안아줘 yoncé saya</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> all night </s>\n",
      "Predicted title:  <s> twice costumes</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> diplomatic immunity </s>\n",
      "Predicted title:  <s> portland sorry</s>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Actual title:  <s> bury a friend elijah hill remix </s>\n",
      "Predicted title:  <s> star 팔도강산 must edit 뭐해 vogue</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> green light hba remix </s>\n",
      "Predicted title:  <s> si bling alone left</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> special </s>\n",
      "Predicted title:  <s> 92nd</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> do not disturb </s>\n",
      "Predicted title:  <s> feel net ignant</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> thank u next jennifer coolidge and ariana grande conversation </s>\n",
      "Predicted title:  <s> champagne alive such yes buenos troyboi not simms bonnie</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> runaway girl </s>\n",
      "Predicted title:  <s> enmore after</s>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Actual title:  <s> crazy in love remix </s>\n",
      "Predicted title:  <s> 작은 my 5 eclipse</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> i don t care </s>\n",
      "Predicted title:  <s> いいね albert stupid lovin</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> blow </s>\n",
      "Predicted title:  <s> thrill</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> love yourself 結 answer notes </s>\n",
      "Predicted title:  <s> green 24 young la il</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> chicago freestyle </s>\n",
      "Predicted title:  <s> gets santa</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> good ones go interlude </s>\n",
      "Predicted title:  <s> tomorrow de justin luck</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> video girl </s>\n",
      "Predicted title:  <s> goodbye will</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> let me love you </s>\n",
      "Predicted title:  <s> two music euphoria prologue</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> same mistakes fall for your type </s>\n",
      "Predicted title:  <s> betty copy dangerously xanny suitcase tears</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> world wide woman </s>\n",
      "Predicted title:  <s> favorite stoned city</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> charlie brown jacques lu cont remix </s>\n",
      "Predicted title:  <s> dogs tint jessi tonight bbc lift</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> outro her </s>\n",
      "Predicted title:  <s> wake journey</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> copycat sofi tukker remix </s>\n",
      "Predicted title:  <s> soon bad somewhere sleep</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> outro speak my mind </s>\n",
      "Predicted title:  <s> henrik abc 00 sound</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> stop sign </s>\n",
      "Predicted title:  <s> when open</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> midnight henrik schwarz remix </s>\n",
      "Predicted title:  <s> wan 10 rebel akay</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> in my place </s>\n",
      "Predicted title:  <s> then link feel</s>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Actual title:  <s> you should see me in a crown iizi remix </s>\n",
      "Predicted title:  <s> damn losses 날이 chariot bet retro spine rosé thank</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> if i were a boy </s>\n",
      "Predicted title:  <s> 힙합성애자 christmas black money woman</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> party favor mahogany sessions </s>\n",
      "Predicted title:  <s> solange till formation arms</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> lost live at the united center chicago il </s>\n",
      "Predicted title:  <s> hurt anger net attention coast cat drop bottom</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> child s play </s>\n",
      "Predicted title:  <s> push idea favour</s>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Actual title:  <s> ghost </s>\n",
      "Predicted title:  <s> tú</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> love on top homecoming live </s>\n",
      "Predicted title:  <s> push 위한 anpanman dark machine</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> knew better forever boy dwt version </s>\n",
      "Predicted title:  <s> tonight euphoria speach beret hair was</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> river </s>\n",
      "Predicted title:  <s> everybody</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> war nala interlude </s>\n",
      "Predicted title:  <s> bodied moon hat</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> voodoo love </s>\n",
      "Predicted title:  <s> connect hop</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> not just on christmas </s>\n",
      "Predicted title:  <s> bucket guess smash album</s>\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Actual title:  <s> problem no rap version </s>\n",
      "Predicted title:  <s> 위한 need mad freakum</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> make it right japanese ver </s>\n",
      "Predicted title:  <s> snl 꺼줄래 top there coolplay</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> do what you do remix </s>\n",
      "Predicted title:  <s> deep 結 잠시 shhh j</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> intro o rul8 2 </s>\n",
      "Predicted title:  <s> riddim lit houstatlantavegas hand</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> paradise tiësto remix </s>\n",
      "Predicted title:  <s> las empty junior</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> boys that sing </s>\n",
      "Predicted title:  <s> trick bloom chariot</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> successful demo </s>\n",
      "Predicted title:  <s> simms liberty</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> major minus single version </s>\n",
      "Predicted title:  <s> care bout beyonce proof</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> denial poem </s>\n",
      "Predicted title:  <s> spot lesson</s>\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Actual title:  <s> house of cards full length edition </s>\n",
      "Predicted title:  <s> use losing sofi 8 hold lovers</s>\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Actual title:  <s> up all night </s>\n",
      "Predicted title:  <s> 소우주 blind second</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> in my head interlude live </s>\n",
      "Predicted title:  <s> ligera santa redemption nu moment</s>\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Actual title:  <s> love maze </s>\n",
      "Predicted title:  <s> dumb sick</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> nasa live </s>\n",
      "Predicted title:  <s> 고엽 dravs</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> daylight </s>\n",
      "Predicted title:  <s> flies</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> coffee </s>\n",
      "Predicted title:  <s> ad</s>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Actual title:  <s> single ladies put a ring on it </s>\n",
      "Predicted title:  <s> bloodless ep grammy myth bahasa 어디에서 runaway</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> if i ruled the world </s>\n",
      "Predicted title:  <s> coolplay gift award 친구 destiny</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> ma city </s>\n",
      "Predicted title:  <s> vital aporia</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> be with you </s>\n",
      "Predicted title:  <s> second adventure valen</s>\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Actual title:  <s> vital </s>\n",
      "Predicted title:  <s> dancing</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> successful </s>\n",
      "Predicted title:  <s> ready</s>\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Actual title:  <s> come real </s>\n",
      "Predicted title:  <s> save gq</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> name it </s>\n",
      "Predicted title:  <s> still stop</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> formation homecoming live </s>\n",
      "Predicted title:  <s> 보조개 coated gone</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> hey goldmember </s>\n",
      "Predicted title:  <s> ignant toronto</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> watch xie remix </s>\n",
      "Predicted title:  <s> pieces jodeci stripper</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> come thru </s>\n",
      "Predicted title:  <s> spiderwebs twice</s>\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Actual title:  <s> 34 35 </s>\n",
      "Predicted title:  <s> flawless eve</s>\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Actual title:  <s> bitter sweet symphony </s>\n",
      "Predicted title:  <s> sweat moroder gravity</s>\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Actual title:  <s> speed of sound </s>\n",
      "Predicted title:  <s> notes gazzo ralphi</s>\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Actual title:  <s> so amazing </s>\n",
      "Predicted title:  <s> moroder poppyfields</s>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Actual title:  <s> make it right acoustic remix </s>\n",
      "Predicted title:  <s> tristan the bad take work</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> 2학년 second grade </s>\n",
      "Predicted title:  <s> bedroom patient equality</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> always in my head live in buenos aires </s>\n",
      "Predicted title:  <s> clay vogue models spot verse bickenhead topless stand</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> thinking bout you </s>\n",
      "Predicted title:  <s> ride breaker madiba</s>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Actual title:  <s> thank you letter </s>\n",
      "Predicted title:  <s> over xo flames</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> baby boy live </s>\n",
      "Predicted title:  <s> seoul god gyalchester</s>\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Actual title:  <s> solid ground </s>\n",
      "Predicted title:  <s> solange lose</s>\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Actual title:  <s> x marks the spot </s>\n",
      "Predicted title:  <s> 더 creole dream d</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> love me harder kassiano remix </s>\n",
      "Predicted title:  <s> proud topic sleep e ホルモン戦争</s>\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Actual title:  <s> midnight </s>\n",
      "Predicted title:  <s> ma</s>\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Actual title:  <s> die with you </s>\n",
      "Predicted title:  <s> stadium sense redemption</s>\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Actual title:  <s> 6 man </s>\n",
      "Predicted title:  <s> jackin bare</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> before i let go </s>\n",
      "Predicted title:  <s> ego when days 2003</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> light up </s>\n",
      "Predicted title:  <s> wildfire need</s>\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Actual title:  <s> heroes </s>\n",
      "Predicted title:  <s> spanish</s>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Actual title:  <s> free </s>\n",
      "Predicted title:  <s> shiver</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> cry cry cry reimagined </s>\n",
      "Predicted title:  <s> quit last schnauss focus</s>\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Actual title:  <s> 7 11 homecoming live </s>\n",
      "Predicted title:  <s> flames tears heartbeat got</s>\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Actual title:  <s> single ladies put a ring on it dj escape tony coluccio remix club version </s>\n",
      "Predicted title:  <s> 8 crack heroes light congratulations star fine face rebel man rockwilder length jason don</s>\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Actual title:  <s> knew better part two </s>\n",
      "Predicted title:  <s> 쩔어 world rose family</s>\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Actual title:  <s> all this love </s>\n",
      "Predicted title:  <s> phone won anger</s>\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Actual title:  <s> behind barz </s>\n",
      "Predicted title:  <s> fingers 14</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> bad decisions </s>\n",
      "Predicted title:  <s> indica goin</s>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Actual title:  <s> epilogue young forever </s>\n",
      "Predicted title:  <s> 전쟁 bug unstoppable</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> daddy </s>\n",
      "Predicted title:  <s> certified</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> i don t know i just wish i wasn t breathing </s>\n",
      "Predicted title:  <s> 2011 debut t culture town empire dick stone peppuse amor leave</s>\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Actual title:  <s> talk leaked version </s>\n",
      "Predicted title:  <s> hall vu link</s>\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Actual title:  <s> desires </s>\n",
      "Predicted title:  <s> florida</s>\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Actual title:  <s> bts cypher pt 2 triptych </s>\n",
      "Predicted title:  <s> 흔한 minus on si white</s>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Actual title:  <s> 2011 juno awards in toronto </s>\n",
      "Predicted title:  <s> desire nothings rebel mine awards</s>\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Actual title:  <s> one dance </s>\n",
      "Predicted title:  <s> 좀 family</s>\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Actual title:  <s> ave maria </s>\n",
      "Predicted title:  <s> breathing photobook</s>\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Actual title:  <s> stunt hard </s>\n",
      "Predicted title:  <s> grave reference</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> is there more </s>\n",
      "Predicted title:  <s> losses friends goldhouse</s>\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Actual title:  <s> god is a woman </s>\n",
      "Predicted title:  <s> lovin sidney goin vibe</s>\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Actual title:  <s> fever </s>\n",
      "Predicted title:  <s> right</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> 호르몬 전쟁 war of hormone </s>\n",
      "Predicted title:  <s> wedding wawa photobook away yeti</s>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Actual title:  <s> watch cole jackson remix </s>\n",
      "Predicted title:  <s> spheres ta 말하자면 than</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> into you </s>\n",
      "Predicted title:  <s> some fedez</s>\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Actual title:  <s> xanny </s>\n",
      "Predicted title:  <s> still</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> you don t love me no no no homecoming live </s>\n",
      "Predicted title:  <s> titled 1st 진심 nu 70s radio comments cool strawberry mrs</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> santa tell me </s>\n",
      "Predicted title:  <s> shoes grammys yoncé</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> juice </s>\n",
      "Predicted title:  <s> about</s>\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Actual title:  <s> formation album version </s>\n",
      "Predicted title:  <s> sense 305 phones</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> i been on homecoming live </s>\n",
      "Predicted title:  <s> leaving adam swagger tet atlantic</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> everyday </s>\n",
      "Predicted title:  <s> borderline</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> jealous </s>\n",
      "Predicted title:  <s> stone</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> top off homecoming live </s>\n",
      "Predicted title:  <s> música from jammin patient</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> i love you live at third man records </s>\n",
      "Predicted title:  <s> until 바다 henrik post bands 좋은 gave eternal</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> a l i e n s </s>\n",
      "Predicted title:  <s> uk donk moment indonesia aoki nasa</s>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Actual title:  <s> goodnight n go live </s>\n",
      "Predicted title:  <s> let sweet control cups</s>\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Actual title:  <s> gift from virgo </s>\n",
      "Predicted title:  <s> wu please 흔한</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> 7 rings live </s>\n",
      "Predicted title:  <s> obvious songbird hurting</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> apology to fans </s>\n",
      "Predicted title:  <s> needy ave final</s>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Actual title:  <s> let me know </s>\n",
      "Predicted title:  <s> shadows grant birds</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> money </s>\n",
      "Predicted title:  <s> def</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> death and all his friends </s>\n",
      "Predicted title:  <s> needs superpower jerry dream anger</s>\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Actual title:  <s> don t hurt yourself </s>\n",
      "Predicted title:  <s> drop 305 tear would</s>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Actual title:  <s> u f o </s>\n",
      "Predicted title:  <s> around til lost</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> yesterday live at the 92nd academy awards </s>\n",
      "Predicted title:  <s> riddim express knows mic lit social loving</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> check on it bama boyz remix </s>\n",
      "Predicted title:  <s> court pov rollin flaws why if</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> could be us </s>\n",
      "Predicted title:  <s> eilish 18th mi</s>\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Actual title:  <s> bitches broken hearts killer frost remix </s>\n",
      "Predicted title:  <s> december diss let aquadrop was yoncé</s>\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Actual title:  <s> make me proud </s>\n",
      "Predicted title:  <s> stars leather dumb</s>\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Actual title:  <s> in the dark </s>\n",
      "Predicted title:  <s> thru atlantica century</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> 6 inch </s>\n",
      "Predicted title:  <s> everybody silver</s>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Actual title:  <s> the winner </s>\n",
      "Predicted title:  <s> bodied desiigner</s>\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Actual title:  <s> at last </s>\n",
      "Predicted title:  <s> angel before</s>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Actual title:  <s> side pieces </s>\n",
      "Predicted title:  <s> tattooed 40</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> beautiful corruption </s>\n",
      "Predicted title:  <s> </s> mine</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> we on </s>\n",
      "Predicted title:  <s> buy path</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> girlfriend </s>\n",
      "Predicted title:  <s> motion</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> black parade remix </s>\n",
      "Predicted title:  <s> debut duke hop</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> sometimes it snows in april </s>\n",
      "Predicted title:  <s> version 2000 beyoncé 시 living</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> how i look on you </s>\n",
      "Predicted title:  <s> nicki 상남자 step hoes just</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> inner child </s>\n",
      "Predicted title:  <s> pain wishing</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> with you </s>\n",
      "Predicted title:  <s> lick 134340</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> would you love me </s>\n",
      "Predicted title:  <s> 시차 war n lord</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> sweetener live </s>\n",
      "Predicted title:  <s> 길 please</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> how long </s>\n",
      "Predicted title:  <s> bombs siembab</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> on </s>\n",
      "Predicted title:  <s> positions</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> new shoes </s>\n",
      "Predicted title:  <s> shoes his</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> déjà vu homecoming live </s>\n",
      "Predicted title:  <s> ve year rocket flip</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> lust for life </s>\n",
      "Predicted title:  <s> unfinished hymn yellow</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> my boy </s>\n",
      "Predicted title:  <s> upset lights</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> sauce boyz </s>\n",
      "Predicted title:  <s> whiley blue</s>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Actual title:  <s> now my feet won t touch the ground </s>\n",
      "Predicted title:  <s> sniffer quarantine cece underneath wap york we round</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> apathy </s>\n",
      "Predicted title:  <s> the</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> we don t talk anymore </s>\n",
      "Predicted title:  <s> material tim court darling away</s>\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Actual title:  <s> sweetener world tour special guests </s>\n",
      "Predicted title:  <s> hearted burn tomorrow twisted otherside</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> 바다 sea </s>\n",
      "Predicted title:  <s> arirang blood</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> teach u a lesson freestyle </s>\n",
      "Predicted title:  <s> weekend duke ve can birthday</s>\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Actual title:  <s> i do remix verse </s>\n",
      "Predicted title:  <s> virgo drop leak right</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> it ain t right </s>\n",
      "Predicted title:  <s> tracks moonlight favorite horn</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> magic </s>\n",
      "Predicted title:  <s> vie</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> still in love kissing you </s>\n",
      "Predicted title:  <s> بنی always family amsterdam for</s>\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Actual title:  <s> fix you four tet remix </s>\n",
      "Predicted title:  <s> greatness yours untitled freakum flyboy</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> booty </s>\n",
      "Predicted title:  <s> bar</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> swallowed in the sea </s>\n",
      "Predicted title:  <s> politik pre spheres through</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> one i love </s>\n",
      "Predicted title:  <s> spanglish dark quixote</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> airplane pt 2 japanese ver </s>\n",
      "Predicted title:  <s> same pianist compares information 30</s>\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Actual title:  <s> black parade </s>\n",
      "Predicted title:  <s> rollin cameras</s>\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Actual title:  <s> in my head music video version </s>\n",
      "Predicted title:  <s> toosie feminism experience quarantine ass daydreamin</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> you re so beautiful </s>\n",
      "Predicted title:  <s> peak hazey 둘 kingdom</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> be alright live </s>\n",
      "Predicted title:  <s> is bow blaster</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> school </s>\n",
      "Predicted title:  <s> tangerine</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> one last time gazzo remix </s>\n",
      "Predicted title:  <s> 전쟁 rewind introduction blind mistakes</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> imagine </s>\n",
      "Predicted title:  <s> soop</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> èkó </s>\n",
      "Predicted title:  <s> walk</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> wednesday night interlude </s>\n",
      "Predicted title:  <s> far coolplay sky</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> bonnie and clyde medley the beyonce experience live </s>\n",
      "Predicted title:  <s> balvin bria told hopex darling hurt tristan lessons</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> easy to please </s>\n",
      "Predicted title:  <s> ring duppy countdown</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> you ll never know </s>\n",
      "Predicted title:  <s> morgan cried problem quotes</s>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Actual title:  <s> yellow acoustic from jo whiley lunchtime social </s>\n",
      "Predicted title:  <s> diplomatic pretty care rings albert buenos ii</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> apology for autism line </s>\n",
      "Predicted title:  <s> thinking monologue winner dates</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> beyoncé com homepage message </s>\n",
      "Predicted title:  <s> hormone aquadrop mix midnight</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> lovin it </s>\n",
      "Predicted title:  <s> reply tickle</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> started </s>\n",
      "Predicted title:  <s> roasting</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> i m alone now </s>\n",
      "Predicted title:  <s> slide attack harmless bloodline</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> jodeci freestyle </s>\n",
      "Predicted title:  <s> jason earls</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> no tears left to cry </s>\n",
      "Predicted title:  <s> belong amor flags moi idontwannabeyouanymore</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> s t r e s s </s>\n",
      "Predicted title:  <s> tattooed tomorrow at pianist nasa 어디에서</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> my gospel </s>\n",
      "Predicted title:  <s> 말하자면 forward</s>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Actual title:  <s> encore for the fans </s>\n",
      "Predicted title:  <s> phones summertime tukker country</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> die in your arms justin bieber </s>\n",
      "Predicted title:  <s> by halo unknown friend argentina goodbye</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> kitty kat </s>\n",
      "Predicted title:  <s> trap apathy</s>\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "Actual title:  <s> 34 35 dj siembab remix </s>\n",
      "Predicted title:  <s> roc welcome hair oceans rain</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> nasty </s>\n",
      "Predicted title:  <s> photobook</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> amor argentina live in buenos aires </s>\n",
      "Predicted title:  <s> get rather speach broadway irreemplazable telegraph</s>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Actual title:  <s> piano early version </s>\n",
      "Predicted title:  <s> loving recorded cosmic</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> december </s>\n",
      "Predicted title:  <s> 9</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> broken reimagined </s>\n",
      "Predicted title:  <s> chant page</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> st stephen </s>\n",
      "Predicted title:  <s> here film</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> make it right remix </s>\n",
      "Predicted title:  <s> slime kick euphoria 연습생의</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> god is a woman hopex remix </s>\n",
      "Predicted title:  <s> 시차 thing davidson thank bama shady</s>\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Actual title:  <s> on remix </s>\n",
      "Predicted title:  <s> diamond sun</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> loving you no more </s>\n",
      "Predicted title:  <s> naughty spine language 불타오르네</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> pound cake paris morton music 2 </s>\n",
      "Predicted title:  <s> rastafarian calderone there phile 뱁새 moon</s>\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Actual title:  <s> daddy lessons remix </s>\n",
      "Predicted title:  <s> speed 전쟁 unreleased</s>\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Actual title:  <s> church </s>\n",
      "Predicted title:  <s> respect</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> my future </s>\n",
      "Predicted title:  <s> 좀 milli</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> party favor ityo boiiii remix </s>\n",
      "Predicted title:  <s> freedom fleek wawa pt sg</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> suga mama </s>\n",
      "Predicted title:  <s> desires us</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> she s broken sunny bare remix </s>\n",
      "Predicted title:  <s> a center ran grenade آدم kick</s>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Actual title:  <s> if you leave me now </s>\n",
      "Predicted title:  <s> dis body throw بنی guy</s>\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Actual title:  <s> teenage fever </s>\n",
      "Predicted title:  <s> tim prologue</s>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Actual title:  <s> self titled part 1 the visual album </s>\n",
      "Predicted title:  <s> ground goldrush wish smile madiba much vegas</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> wap demo </s>\n",
      "Predicted title:  <s> las bonnie</s>\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Actual title:  <s> beautiful music </s>\n",
      "Predicted title:  <s> 병 man</s>\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Actual title:  <s> intro live </s>\n",
      "Predicted title:  <s> harmless spiderwebs</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> flawless remix </s>\n",
      "Predicted title:  <s> 소우주 i</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> not afraid of love </s>\n",
      "Predicted title:  <s> ice karmatronic every tattoos</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> right there ralphi rosario radio </s>\n",
      "Predicted title:  <s> bootylicious speach extended missin letter</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> too good </s>\n",
      "Predicted title:  <s> 24 trap</s>\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Actual title:  <s> you should see me in a crown </s>\n",
      "Predicted title:  <s> feat soop 承 truck beyoncé 起 vs</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> when the party s over </s>\n",
      "Predicted title:  <s> rollercoaster siembab samson paldogangsan jail</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> bad </s>\n",
      "Predicted title:  <s> wedding</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> breathin </s>\n",
      "Predicted title:  <s> smoke</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> thank u next quotes </s>\n",
      "Predicted title:  <s> mix barry hardwell prologue</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> one call away </s>\n",
      "Predicted title:  <s> trophies under 더</s>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Actual title:  <s> star67 </s>\n",
      "Predicted title:  <s> work</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> idol japanese ver </s>\n",
      "Predicted title:  <s> goodbye until いいね</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> fly on </s>\n",
      "Predicted title:  <s> sauce hei</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> clocks röyksopp trembling heart remix </s>\n",
      "Predicted title:  <s> statement wasn bombs grant liberty</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> why don t you love me </s>\n",
      "Predicted title:  <s> express jodeci automatic blaum cover uk</s>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Actual title:  <s> hold up </s>\n",
      "Predicted title:  <s> tony jungle</s>\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Actual title:  <s> sweetener world tour dates </s>\n",
      "Predicted title:  <s> sober freestyle drunk 가요</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> ホルモン戦争 war of hormone japanese ver </s>\n",
      "Predicted title:  <s> phantoms kingdom heroes true aude ariana</s>\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Actual title:  <s> pray you catch me </s>\n",
      "Predicted title:  <s> bickenhead scared scientist reply</s>\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Actual title:  <s> find your way back melo x remix </s>\n",
      "Predicted title:  <s> awards en dogs twinsmatic grind tribute fancy</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> how do you see me </s>\n",
      "Predicted title:  <s> arms houston tropical emotions morgan</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> party homecoming live </s>\n",
      "Predicted title:  <s> 36 jennifer made</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> up </s>\n",
      "Predicted title:  <s> sexuality</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> unforgettable </s>\n",
      "Predicted title:  <s> oh</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> bodak yellow latin trap remix </s>\n",
      "Predicted title:  <s> morton social court orphans justin</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> bootylicious live </s>\n",
      "Predicted title:  <s> telegraph not</s>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Actual title:  <s> first steps </s>\n",
      "Predicted title:  <s> un suzanne</s>\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Actual title:  <s> 2016 mtv vmas vanguard award intro for rihanna </s>\n",
      "Predicted title:  <s> bullets billie ten put story year sessions juice</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> she got her own demo edit </s>\n",
      "Predicted title:  <s> addiction 6pm lifetime west push pt</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> 血 汗 淚 blood sweat tears japanese ver </s>\n",
      "Predicted title:  <s> god piper revolution what spent 9 soon motion</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> outro </s>\n",
      "Predicted title:  <s> oughta</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> deja vu beyoncé experience live </s>\n",
      "Predicted title:  <s> connect hold indica cameras stephen</s>\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Actual title:  <s> ocean eyes </s>\n",
      "Predicted title:  <s> brooklyn eva</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> fighting temptation </s>\n",
      "Predicted title:  <s> f blue</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> touch it </s>\n",
      "Predicted title:  <s> 피 upgrade</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> i m somebody </s>\n",
      "Predicted title:  <s> quotes lunchtime track</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> redemption </s>\n",
      "Predicted title:  <s> looks</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> dionysus japanese ver </s>\n",
      "Predicted title:  <s> track postcards way</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> murder </s>\n",
      "Predicted title:  <s> lights</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> proud to be an american </s>\n",
      "Predicted title:  <s> astronomyy everybody your evil she</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> thank you note to 40 </s>\n",
      "Predicted title:  <s> grave 2017 rossi luck bieber</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> intro </s>\n",
      "Predicted title:  <s> karaoke</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> the light is coming live </s>\n",
      "Predicted title:  <s> eva empty message clyde low</s>\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Actual title:  <s> only superstition </s>\n",
      "Predicted title:  <s> 4pm rain</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> i got ta hurt you </s>\n",
      "Predicted title:  <s> بنی 뭐해 rockin 핸드폰 상남자</s>\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Actual title:  <s> spring day japanese ver </s>\n",
      "Predicted title:  <s> rodg if catch cut</s>\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Actual title:  <s> lovin you lately </s>\n",
      "Predicted title:  <s> barker costumes si</s>\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Actual title:  <s> side to side slushii remix </s>\n",
      "Predicted title:  <s> naderi assembly old end anymore</s>\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Actual title:  <s> up in flames </s>\n",
      "Predicted title:  <s> bangtan luv november</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> home </s>\n",
      "Predicted title:  <s> corner</s>\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Actual title:  <s> the hardest part tom lord alge mix </s>\n",
      "Predicted title:  <s> home rodg 낙원 he frostremix bollywood moment</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> god s plan </s>\n",
      "Predicted title:  <s> grammys murder frostremix</s>\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Actual title:  <s> shiver live in sydney </s>\n",
      "Predicted title:  <s> gypsy after summers waiting</s>\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Actual title:  <s> end of time </s>\n",
      "Predicted title:  <s> panic maurice 1975</s>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Actual title:  <s> mic drop steve aoki remix </s>\n",
      "Predicted title:  <s> jacques birthday cups see somebody</s>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Actual title:  <s> obvious </s>\n",
      "Predicted title:  <s> heart</s>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Actual title:  <s> get well soon </s>\n",
      "Predicted title:  <s> speed strawberry script</s>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Actual title:  <s> crew love </s>\n",
      "Predicted title:  <s> akay salto</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> miss me </s>\n",
      "Predicted title:  <s> lewis mic</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> life in technicolor ii </s>\n",
      "Predicted title:  <s> 8 música signs ホルモン戦争</s>\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Actual title:  <s> i warned myself </s>\n",
      "Predicted title:  <s> luv some 말이</s>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Actual title:  <s> hymn for the weekend seeb remix </s>\n",
      "Predicted title:  <s> apology shiver goodnight brit gone footlong</s>\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Actual title:  <s> right there you ll never know break your heart right back </s>\n",
      "Predicted title:  <s> soul wayne conquer season legend messages nothing album losses </s> rossi</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> west side </s>\n",
      "Predicted title:  <s> elijah higher</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> interlude wings </s>\n",
      "Predicted title:  <s> 35 wet</s>\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Actual title:  <s> madiba riddim </s>\n",
      "Predicted title:  <s> 잡아줘 born</s>\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Actual title:  <s> they don t know </s>\n",
      "Predicted title:  <s> away ridiculous interlude reply</s>\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Actual title:  <s> greedy </s>\n",
      "Predicted title:  <s> gyalchester</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> single ladies put a ring on it homecoming live </s>\n",
      "Predicted title:  <s> lift disturb tet tattooed army gay list emotions worst</s>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Actual title:  <s> begin </s>\n",
      "Predicted title:  <s> six</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> peak </s>\n",
      "Predicted title:  <s> release</s>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Actual title:  <s> 진격의 방탄 attack on bangtan the rise of bangtan </s>\n",
      "Predicted title:  <s> grande los eclipse pain edit equality rodg suga 가요대축제</s>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Actual title:  <s> try harder </s>\n",
      "Predicted title:  <s> lunchtime needy</s>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Actual title:  <s> lost yo mind </s>\n",
      "Predicted title:  <s> song 피 never</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> one last time marshmello remix </s>\n",
      "Predicted title:  <s> bootleg spheres stand drum bastard</s>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Actual title:  <s> run alternative mix </s>\n",
      "Predicted title:  <s> later brave team</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> ridiculous </s>\n",
      "Predicted title:  <s> bonnie</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> bitches broken hearts </s>\n",
      "Predicted title:  <s> r joshua c</s>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Actual title:  <s> good day </s>\n",
      "Predicted title:  <s> open bootylicious</s>\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Actual title:  <s> views </s>\n",
      "Predicted title:  <s> issues</s>\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Actual title:  <s> wap </s>\n",
      "Predicted title:  <s> mojo</s>\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Actual title:  <s> settle 4 u </s>\n",
      "Predicted title:  <s> turn ak tristan</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> shiver acoustic from jo whiley lunchtime social </s>\n",
      "Predicted title:  <s> blow nations 꺼줄래 fall baby copy 3</s>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Actual title:  <s> proof </s>\n",
      "Predicted title:  <s> general</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> me u </s>\n",
      "Predicted title:  <s> slime jammin</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> listen </s>\n",
      "Predicted title:  <s> brooklyn</s>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Actual title:  <s> party </s>\n",
      "Predicted title:  <s> only</s>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Actual title:  <s> what if </s>\n",
      "Predicted title:  <s> head liar</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> flags </s>\n",
      "Predicted title:  <s> thrones</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> nonstop </s>\n",
      "Predicted title:  <s> round</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> lovers in japan osaka sun mix </s>\n",
      "Predicted title:  <s> grown t shoulder lucky conquer used</s>\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Actual title:  <s> call me back </s>\n",
      "Predicted title:  <s> since johnny atlantica</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> summer games </s>\n",
      "Predicted title:  <s> 말이 sweetener</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> cemeteries of london </s>\n",
      "Predicted title:  <s> tough blueberries beer</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> empty cups </s>\n",
      "Predicted title:  <s> pistols enmore</s>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Actual title:  <s> have yourself a merry little christmas </s>\n",
      "Predicted title:  <s> link must denial wedding creole 왔는지</s>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Actual title:  <s> what i m thinkin right now </s>\n",
      "Predicted title:  <s> kangaroos energy cardi flaws vertigo murder</s>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Actual title:  <s> bad </s>\n",
      "Predicted title:  <s> peak</s>\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "Actual title:  <s> six feet under gazzo remix </s>\n",
      "Predicted title:  <s> enmore sparks 16 lemonade dravs</s>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Actual title:  <s> honeymoon avenue </s>\n",
      "Predicted title:  <s> mitzvah girl</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> done for me </s>\n",
      "Predicted title:  <s> mitzvah special bombs</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> the mrs carter show </s>\n",
      "Predicted title:  <s> holiday champagne rossi need</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> the search </s>\n",
      "Predicted title:  <s> oye next</s>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Actual title:  <s> i was here </s>\n",
      "Predicted title:  <s> stadium transcription jealous</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> positions clean </s>\n",
      "Predicted title:  <s> attends verse</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> goodbye </s>\n",
      "Predicted title:  <s> court</s>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Actual title:  <s> fancy </s>\n",
      "Predicted title:  <s> settle</s>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Actual title:  <s> broken hearted girl live </s>\n",
      "Predicted title:  <s> changes spine alarm blood</s>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Actual title:  <s> true love live at the enmore theatre sydney </s>\n",
      "Predicted title:  <s> signs friends seventeen rosario comeback 땀 wings 汗</s>\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Actual title:  <s> reply 2 this </s>\n",
      "Predicted title:  <s> acoustic yamaha motto</s>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Actual title:  <s> i did grand entrance </s>\n",
      "Predicted title:  <s> therefore marvin livesver 이불킥</s>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Actual title:  <s> imagine my favorite things 7 rings thank u next live at the 62nd grammy awards </s>\n",
      "Predicted title:  <s> 흔한 machine moses edition usual alone 것들을 mistakes marks 위한 eres 進撃の防弾 spirit macklemore keep</s>\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Actual title:  <s> signs </s>\n",
      "Predicted title:  <s> guide</s>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Actual title:  <s> ocean eyes astronomyy remix </s>\n",
      "Predicted title:  <s> poolside 진격의 nothing lies</s>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Actual title:  <s> suga mama remix </s>\n",
      "Predicted title:  <s> 2019 scriptures look</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> party favor </s>\n",
      "Predicted title:  <s> diss favor</s>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Actual title:  <s> ego ok dac remix </s>\n",
      "Predicted title:  <s> ruled spanish fever dumb</s>\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Actual title:  <s> euphoria </s>\n",
      "Predicted title:  <s> thrill</s>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Actual title:  <s> still going strong </s>\n",
      "Predicted title:  <s> mariah understand alone</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> what s good with you </s>\n",
      "Predicted title:  <s> 2010 abc missin dna rosario</s>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Actual title:  <s> she s broken </s>\n",
      "Predicted title:  <s> release center cautious</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s> invented thrill nala</s>',\n",
       " '<s> daylight sydney night</s>',\n",
       " '<s> november</s>',\n",
       " '<s> freestyle</s>',\n",
       " '<s> rebel bigger 轉</s>',\n",
       " '<s> 잠시</s>',\n",
       " '<s> bonds</s>',\n",
       " '<s> edit new summer 1999 hills</s>',\n",
       " '<s> yourself</s>',\n",
       " '<s> motto lust moses</s>',\n",
       " '<s> black 학교의눈물 d about settle</s>',\n",
       " '<s> florida own under da</s>',\n",
       " '<s> gay bands cream</s>',\n",
       " '<s> strawberry</s>',\n",
       " '<s> light control days</s>',\n",
       " '<s> intoxicated around yoncé ballad</s>',\n",
       " '<s> hide that f</s>',\n",
       " '<s> dance left boy need</s>',\n",
       " '<s> siembab</s>',\n",
       " '<s> money more street</s>',\n",
       " '<s> wizard ペップセ show theatre pain</s>',\n",
       " '<s> as bria 11 dollar critiquing</s>',\n",
       " '<s> cred catalyst 6pm rather jaded</s>',\n",
       " '<s> tú mind èkó goode stand 꺼줄래</s>',\n",
       " '<s> madonna c into cred coluccio</s>',\n",
       " '<s> bangtan florida kevorkian</s>',\n",
       " '<s> seoul faded sex</s>',\n",
       " '<s> logic donk</s>',\n",
       " '<s> terjemahan city road jochen</s>',\n",
       " '<s> fantasy 흔한 nonstop answer</s>',\n",
       " '<s> off</s>',\n",
       " '<s> seeb 힙합성애자</s>',\n",
       " '<s> west trivia all xo press 起 ode</s>',\n",
       " '<s> first salto sun</s>',\n",
       " '<s> 고엽 módl eilish giorgio</s>',\n",
       " '<s> missin resentment ve violet 100 rihanna maurice summertime 40</s>',\n",
       " '<s> elijah mad 18th</s>',\n",
       " '<s> dynamite begin gon hands head</s>',\n",
       " '<s> fight あの場所で best</s>',\n",
       " '<s> dead scared</s>',\n",
       " '<s> shot</s>',\n",
       " '<s> ad</s>',\n",
       " '<s> thrill afraid barry tribute lethal major roc scientist</s>',\n",
       " '<s> boyz patient</s>',\n",
       " '<s> 1xtra sidney</s>',\n",
       " '<s> teach quarantine</s>',\n",
       " '<s> touch this grave looks 92nd hook</s>',\n",
       " '<s> successful</s>',\n",
       " '<s> not 작은 guess</s>',\n",
       " '<s> valen 좋은</s>',\n",
       " '<s> grown topic</s>',\n",
       " '<s> ligera haunted 땀 tough</s>',\n",
       " '<s> youth at eres</s>',\n",
       " '<s> y amor eva morgan danger</s>',\n",
       " '<s> presentation 2010 bulletproof orphans</s>',\n",
       " '<s> settle gon</s>',\n",
       " '<s> west slow 작은 euphoria bodak</s>',\n",
       " '<s> 크리스마스</s>',\n",
       " '<s> voice know</s>',\n",
       " '<s> bottom 안아줘 yoncé saya</s>',\n",
       " '<s> twice costumes</s>',\n",
       " '<s> portland sorry</s>',\n",
       " '<s> star 팔도강산 must edit 뭐해 vogue</s>',\n",
       " '<s> si bling alone left</s>',\n",
       " '<s> 92nd</s>',\n",
       " '<s> feel net ignant</s>',\n",
       " '<s> champagne alive such yes buenos troyboi not simms bonnie</s>',\n",
       " '<s> enmore after</s>',\n",
       " '<s> 작은 my 5 eclipse</s>',\n",
       " '<s> いいね albert stupid lovin</s>',\n",
       " '<s> thrill</s>',\n",
       " '<s> green 24 young la il</s>',\n",
       " '<s> gets santa</s>',\n",
       " '<s> tomorrow de justin luck</s>',\n",
       " '<s> goodbye will</s>',\n",
       " '<s> two music euphoria prologue</s>',\n",
       " '<s> betty copy dangerously xanny suitcase tears</s>',\n",
       " '<s> favorite stoned city</s>',\n",
       " '<s> dogs tint jessi tonight bbc lift</s>',\n",
       " '<s> wake journey</s>',\n",
       " '<s> soon bad somewhere sleep</s>',\n",
       " '<s> henrik abc 00 sound</s>',\n",
       " '<s> when open</s>',\n",
       " '<s> wan 10 rebel akay</s>',\n",
       " '<s> then link feel</s>',\n",
       " '<s> damn losses 날이 chariot bet retro spine rosé thank</s>',\n",
       " '<s> 힙합성애자 christmas black money woman</s>',\n",
       " '<s> solange till formation arms</s>',\n",
       " '<s> hurt anger net attention coast cat drop bottom</s>',\n",
       " '<s> push idea favour</s>',\n",
       " '<s> tú</s>',\n",
       " '<s> push 위한 anpanman dark machine</s>',\n",
       " '<s> tonight euphoria speach beret hair was</s>',\n",
       " '<s> everybody</s>',\n",
       " '<s> bodied moon hat</s>',\n",
       " '<s> connect hop</s>',\n",
       " '<s> bucket guess smash album</s>',\n",
       " '<s> 위한 need mad freakum</s>',\n",
       " '<s> snl 꺼줄래 top there coolplay</s>',\n",
       " '<s> deep 結 잠시 shhh j</s>',\n",
       " '<s> riddim lit houstatlantavegas hand</s>',\n",
       " '<s> las empty junior</s>',\n",
       " '<s> trick bloom chariot</s>',\n",
       " '<s> simms liberty</s>',\n",
       " '<s> care bout beyonce proof</s>',\n",
       " '<s> spot lesson</s>',\n",
       " '<s> use losing sofi 8 hold lovers</s>',\n",
       " '<s> 소우주 blind second</s>',\n",
       " '<s> ligera santa redemption nu moment</s>',\n",
       " '<s> dumb sick</s>',\n",
       " '<s> 고엽 dravs</s>',\n",
       " '<s> flies</s>',\n",
       " '<s> ad</s>',\n",
       " '<s> bloodless ep grammy myth bahasa 어디에서 runaway</s>',\n",
       " '<s> coolplay gift award 친구 destiny</s>',\n",
       " '<s> vital aporia</s>',\n",
       " '<s> second adventure valen</s>',\n",
       " '<s> dancing</s>',\n",
       " '<s> ready</s>',\n",
       " '<s> save gq</s>',\n",
       " '<s> still stop</s>',\n",
       " '<s> 보조개 coated gone</s>',\n",
       " '<s> ignant toronto</s>',\n",
       " '<s> pieces jodeci stripper</s>',\n",
       " '<s> spiderwebs twice</s>',\n",
       " '<s> flawless eve</s>',\n",
       " '<s> sweat moroder gravity</s>',\n",
       " '<s> notes gazzo ralphi</s>',\n",
       " '<s> moroder poppyfields</s>',\n",
       " '<s> tristan the bad take work</s>',\n",
       " '<s> bedroom patient equality</s>',\n",
       " '<s> clay vogue models spot verse bickenhead topless stand</s>',\n",
       " '<s> ride breaker madiba</s>',\n",
       " '<s> over xo flames</s>',\n",
       " '<s> seoul god gyalchester</s>',\n",
       " '<s> solange lose</s>',\n",
       " '<s> 더 creole dream d</s>',\n",
       " '<s> proud topic sleep e ホルモン戦争</s>',\n",
       " '<s> ma</s>',\n",
       " '<s> stadium sense redemption</s>',\n",
       " '<s> jackin bare</s>',\n",
       " '<s> ego when days 2003</s>',\n",
       " '<s> wildfire need</s>',\n",
       " '<s> spanish</s>',\n",
       " '<s> shiver</s>',\n",
       " '<s> quit last schnauss focus</s>',\n",
       " '<s> flames tears heartbeat got</s>',\n",
       " '<s> 8 crack heroes light congratulations star fine face rebel man rockwilder length jason don</s>',\n",
       " '<s> 쩔어 world rose family</s>',\n",
       " '<s> phone won anger</s>',\n",
       " '<s> fingers 14</s>',\n",
       " '<s> indica goin</s>',\n",
       " '<s> 전쟁 bug unstoppable</s>',\n",
       " '<s> certified</s>',\n",
       " '<s> 2011 debut t culture town empire dick stone peppuse amor leave</s>',\n",
       " '<s> hall vu link</s>',\n",
       " '<s> florida</s>',\n",
       " '<s> 흔한 minus on si white</s>',\n",
       " '<s> desire nothings rebel mine awards</s>',\n",
       " '<s> 좀 family</s>',\n",
       " '<s> breathing photobook</s>',\n",
       " '<s> grave reference</s>',\n",
       " '<s> losses friends goldhouse</s>',\n",
       " '<s> lovin sidney goin vibe</s>',\n",
       " '<s> right</s>',\n",
       " '<s> wedding wawa photobook away yeti</s>',\n",
       " '<s> spheres ta 말하자면 than</s>',\n",
       " '<s> some fedez</s>',\n",
       " '<s> still</s>',\n",
       " '<s> titled 1st 진심 nu 70s radio comments cool strawberry mrs</s>',\n",
       " '<s> shoes grammys yoncé</s>',\n",
       " '<s> about</s>',\n",
       " '<s> sense 305 phones</s>',\n",
       " '<s> leaving adam swagger tet atlantic</s>',\n",
       " '<s> borderline</s>',\n",
       " '<s> stone</s>',\n",
       " '<s> música from jammin patient</s>',\n",
       " '<s> until 바다 henrik post bands 좋은 gave eternal</s>',\n",
       " '<s> uk donk moment indonesia aoki nasa</s>',\n",
       " '<s> let sweet control cups</s>',\n",
       " '<s> wu please 흔한</s>',\n",
       " '<s> obvious songbird hurting</s>',\n",
       " '<s> needy ave final</s>',\n",
       " '<s> shadows grant birds</s>',\n",
       " '<s> def</s>',\n",
       " '<s> needs superpower jerry dream anger</s>',\n",
       " '<s> drop 305 tear would</s>',\n",
       " '<s> around til lost</s>',\n",
       " '<s> riddim express knows mic lit social loving</s>',\n",
       " '<s> court pov rollin flaws why if</s>',\n",
       " '<s> eilish 18th mi</s>',\n",
       " '<s> december diss let aquadrop was yoncé</s>',\n",
       " '<s> stars leather dumb</s>',\n",
       " '<s> thru atlantica century</s>',\n",
       " '<s> everybody silver</s>',\n",
       " '<s> bodied desiigner</s>',\n",
       " '<s> angel before</s>',\n",
       " '<s> tattooed 40</s>',\n",
       " '<s> </s> mine</s>',\n",
       " '<s> buy path</s>',\n",
       " '<s> motion</s>',\n",
       " '<s> debut duke hop</s>',\n",
       " '<s> version 2000 beyoncé 시 living</s>',\n",
       " '<s> nicki 상남자 step hoes just</s>',\n",
       " '<s> pain wishing</s>',\n",
       " '<s> lick 134340</s>',\n",
       " '<s> 시차 war n lord</s>',\n",
       " '<s> 길 please</s>',\n",
       " '<s> bombs siembab</s>',\n",
       " '<s> positions</s>',\n",
       " '<s> shoes his</s>',\n",
       " '<s> ve year rocket flip</s>',\n",
       " '<s> unfinished hymn yellow</s>',\n",
       " '<s> upset lights</s>',\n",
       " '<s> whiley blue</s>',\n",
       " '<s> sniffer quarantine cece underneath wap york we round</s>',\n",
       " '<s> the</s>',\n",
       " '<s> material tim court darling away</s>',\n",
       " '<s> hearted burn tomorrow twisted otherside</s>',\n",
       " '<s> arirang blood</s>',\n",
       " '<s> weekend duke ve can birthday</s>',\n",
       " '<s> virgo drop leak right</s>',\n",
       " '<s> tracks moonlight favorite horn</s>',\n",
       " '<s> vie</s>',\n",
       " '<s> بنی always family amsterdam for</s>',\n",
       " '<s> greatness yours untitled freakum flyboy</s>',\n",
       " '<s> bar</s>',\n",
       " '<s> politik pre spheres through</s>',\n",
       " '<s> spanglish dark quixote</s>',\n",
       " '<s> same pianist compares information 30</s>',\n",
       " '<s> rollin cameras</s>',\n",
       " '<s> toosie feminism experience quarantine ass daydreamin</s>',\n",
       " '<s> peak hazey 둘 kingdom</s>',\n",
       " '<s> is bow blaster</s>',\n",
       " '<s> tangerine</s>',\n",
       " '<s> 전쟁 rewind introduction blind mistakes</s>',\n",
       " '<s> soop</s>',\n",
       " '<s> walk</s>',\n",
       " '<s> far coolplay sky</s>',\n",
       " '<s> balvin bria told hopex darling hurt tristan lessons</s>',\n",
       " '<s> ring duppy countdown</s>',\n",
       " '<s> morgan cried problem quotes</s>',\n",
       " '<s> diplomatic pretty care rings albert buenos ii</s>',\n",
       " '<s> thinking monologue winner dates</s>',\n",
       " '<s> hormone aquadrop mix midnight</s>',\n",
       " '<s> reply tickle</s>',\n",
       " '<s> roasting</s>',\n",
       " '<s> slide attack harmless bloodline</s>',\n",
       " '<s> jason earls</s>',\n",
       " '<s> belong amor flags moi idontwannabeyouanymore</s>',\n",
       " '<s> tattooed tomorrow at pianist nasa 어디에서</s>',\n",
       " '<s> 말하자면 forward</s>',\n",
       " '<s> phones summertime tukker country</s>',\n",
       " '<s> by halo unknown friend argentina goodbye</s>',\n",
       " '<s> trap apathy</s>',\n",
       " '<s> roc welcome hair oceans rain</s>',\n",
       " '<s> photobook</s>',\n",
       " '<s> get rather speach broadway irreemplazable telegraph</s>',\n",
       " '<s> loving recorded cosmic</s>',\n",
       " '<s> 9</s>',\n",
       " '<s> chant page</s>',\n",
       " '<s> here film</s>',\n",
       " '<s> slime kick euphoria 연습생의</s>',\n",
       " '<s> 시차 thing davidson thank bama shady</s>',\n",
       " '<s> diamond sun</s>',\n",
       " '<s> naughty spine language 불타오르네</s>',\n",
       " '<s> rastafarian calderone there phile 뱁새 moon</s>',\n",
       " '<s> speed 전쟁 unreleased</s>',\n",
       " '<s> respect</s>',\n",
       " '<s> 좀 milli</s>',\n",
       " '<s> freedom fleek wawa pt sg</s>',\n",
       " '<s> desires us</s>',\n",
       " '<s> a center ran grenade آدم kick</s>',\n",
       " '<s> dis body throw بنی guy</s>',\n",
       " '<s> tim prologue</s>',\n",
       " '<s> ground goldrush wish smile madiba much vegas</s>',\n",
       " '<s> las bonnie</s>',\n",
       " '<s> 병 man</s>',\n",
       " '<s> harmless spiderwebs</s>',\n",
       " '<s> 소우주 i</s>',\n",
       " '<s> ice karmatronic every tattoos</s>',\n",
       " '<s> bootylicious speach extended missin letter</s>',\n",
       " '<s> 24 trap</s>',\n",
       " '<s> feat soop 承 truck beyoncé 起 vs</s>',\n",
       " '<s> rollercoaster siembab samson paldogangsan jail</s>',\n",
       " '<s> wedding</s>',\n",
       " '<s> smoke</s>',\n",
       " '<s> mix barry hardwell prologue</s>',\n",
       " '<s> trophies under 더</s>',\n",
       " '<s> work</s>',\n",
       " '<s> goodbye until いいね</s>',\n",
       " '<s> sauce hei</s>',\n",
       " '<s> statement wasn bombs grant liberty</s>',\n",
       " '<s> express jodeci automatic blaum cover uk</s>',\n",
       " '<s> tony jungle</s>',\n",
       " '<s> sober freestyle drunk 가요</s>',\n",
       " '<s> phantoms kingdom heroes true aude ariana</s>',\n",
       " '<s> bickenhead scared scientist reply</s>',\n",
       " '<s> awards en dogs twinsmatic grind tribute fancy</s>',\n",
       " '<s> arms houston tropical emotions morgan</s>',\n",
       " '<s> 36 jennifer made</s>',\n",
       " '<s> sexuality</s>',\n",
       " '<s> oh</s>',\n",
       " '<s> morton social court orphans justin</s>',\n",
       " '<s> telegraph not</s>',\n",
       " '<s> un suzanne</s>',\n",
       " '<s> bullets billie ten put story year sessions juice</s>',\n",
       " '<s> addiction 6pm lifetime west push pt</s>',\n",
       " '<s> god piper revolution what spent 9 soon motion</s>',\n",
       " '<s> oughta</s>',\n",
       " '<s> connect hold indica cameras stephen</s>',\n",
       " '<s> brooklyn eva</s>',\n",
       " '<s> f blue</s>',\n",
       " '<s> 피 upgrade</s>',\n",
       " '<s> quotes lunchtime track</s>',\n",
       " '<s> looks</s>',\n",
       " '<s> track postcards way</s>',\n",
       " '<s> lights</s>',\n",
       " '<s> astronomyy everybody your evil she</s>',\n",
       " '<s> grave 2017 rossi luck bieber</s>',\n",
       " '<s> karaoke</s>',\n",
       " '<s> eva empty message clyde low</s>',\n",
       " '<s> 4pm rain</s>',\n",
       " '<s> بنی 뭐해 rockin 핸드폰 상남자</s>',\n",
       " '<s> rodg if catch cut</s>',\n",
       " '<s> barker costumes si</s>',\n",
       " '<s> naderi assembly old end anymore</s>',\n",
       " '<s> bangtan luv november</s>',\n",
       " '<s> corner</s>',\n",
       " '<s> home rodg 낙원 he frostremix bollywood moment</s>',\n",
       " '<s> grammys murder frostremix</s>',\n",
       " '<s> gypsy after summers waiting</s>',\n",
       " '<s> panic maurice 1975</s>',\n",
       " '<s> jacques birthday cups see somebody</s>',\n",
       " '<s> heart</s>',\n",
       " '<s> speed strawberry script</s>',\n",
       " '<s> akay salto</s>',\n",
       " '<s> lewis mic</s>',\n",
       " '<s> 8 música signs ホルモン戦争</s>',\n",
       " '<s> luv some 말이</s>',\n",
       " '<s> apology shiver goodnight brit gone footlong</s>',\n",
       " '<s> soul wayne conquer season legend messages nothing album losses </s> rossi</s>',\n",
       " '<s> elijah higher</s>',\n",
       " '<s> 35 wet</s>',\n",
       " '<s> 잡아줘 born</s>',\n",
       " '<s> away ridiculous interlude reply</s>',\n",
       " '<s> gyalchester</s>',\n",
       " '<s> lift disturb tet tattooed army gay list emotions worst</s>',\n",
       " '<s> six</s>',\n",
       " '<s> release</s>',\n",
       " '<s> grande los eclipse pain edit equality rodg suga 가요대축제</s>',\n",
       " '<s> lunchtime needy</s>',\n",
       " '<s> song 피 never</s>',\n",
       " '<s> bootleg spheres stand drum bastard</s>',\n",
       " '<s> later brave team</s>',\n",
       " '<s> bonnie</s>',\n",
       " '<s> r joshua c</s>',\n",
       " '<s> open bootylicious</s>',\n",
       " '<s> issues</s>',\n",
       " '<s> mojo</s>',\n",
       " '<s> turn ak tristan</s>',\n",
       " '<s> blow nations 꺼줄래 fall baby copy 3</s>',\n",
       " '<s> general</s>',\n",
       " '<s> slime jammin</s>',\n",
       " '<s> brooklyn</s>',\n",
       " '<s> only</s>',\n",
       " '<s> head liar</s>',\n",
       " '<s> thrones</s>',\n",
       " '<s> round</s>',\n",
       " '<s> grown t shoulder lucky conquer used</s>',\n",
       " '<s> since johnny atlantica</s>',\n",
       " '<s> 말이 sweetener</s>',\n",
       " '<s> tough blueberries beer</s>',\n",
       " '<s> pistols enmore</s>',\n",
       " '<s> link must denial wedding creole 왔는지</s>',\n",
       " '<s> kangaroos energy cardi flaws vertigo murder</s>',\n",
       " '<s> peak</s>',\n",
       " '<s> enmore sparks 16 lemonade dravs</s>',\n",
       " '<s> mitzvah girl</s>',\n",
       " '<s> mitzvah special bombs</s>',\n",
       " '<s> holiday champagne rossi need</s>',\n",
       " '<s> oye next</s>',\n",
       " '<s> stadium transcription jealous</s>',\n",
       " '<s> attends verse</s>',\n",
       " '<s> court</s>',\n",
       " '<s> settle</s>',\n",
       " '<s> changes spine alarm blood</s>',\n",
       " '<s> signs friends seventeen rosario comeback 땀 wings 汗</s>',\n",
       " '<s> acoustic yamaha motto</s>',\n",
       " '<s> therefore marvin livesver 이불킥</s>',\n",
       " '<s> 흔한 machine moses edition usual alone 것들을 mistakes marks 위한 eres 進撃の防弾 spirit macklemore keep</s>',\n",
       " '<s> guide</s>',\n",
       " '<s> poolside 진격의 nothing lies</s>',\n",
       " '<s> 2019 scriptures look</s>',\n",
       " '<s> diss favor</s>',\n",
       " '<s> ruled spanish fever dumb</s>',\n",
       " '<s> thrill</s>',\n",
       " '<s> mariah understand alone</s>',\n",
       " '<s> 2010 abc missin dna rosario</s>',\n",
       " '<s> release center cautious</s>']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_titles(model, X_test, y_test, tokenizer, temperature=1.0):\n",
    "    # Map index to word\n",
    "    reverse_word_map = dict(map(reversed, tokenizer.word_index.items())) \n",
    "    \n",
    "    all_predicted_titles = []\n",
    "    all_actual_titles = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        # get the current lyrics\n",
    "        current_song = np.expand_dims(X_test[i], axis=0)\n",
    "        # get the actual title (using helper function from part 1)\n",
    "        actual_title, actual_title_len = convert_one_hot_vectors_to_words(y_test[i], tokenizer) # Get actual title from label\n",
    "\n",
    "        # create probability distribution for words\n",
    "        predictions = model.predict(current_song)\n",
    "\n",
    "        # Initialize list to store predicted words\n",
    "        predicted_words = []\n",
    "\n",
    "        # Sample one word at a time, excluding start and end characters\n",
    "        for timestep in range(actual_title_len - 2):\n",
    "            probs = predictions[0][timestep]\n",
    "            # Exclude start and end characters\n",
    "            probs[0] = 0\n",
    "            probs[-1] = 0\n",
    "            # Apply temperature scaling\n",
    "            probs = np.power(probs, 1.0/temperature)\n",
    "            probs /= np.sum(probs)\n",
    "            # Sample from the probability distribution\n",
    "            word_idx = np.random.choice(len(probs), p=probs)\n",
    "            # Convert index to word\n",
    "            word = reverse_word_map.get(word_idx, 'unk')\n",
    "            predicted_words.append(word)\n",
    "\n",
    "        title = ' '.join(predicted_words)\n",
    "        # add sentence start and end characters to predicted title\n",
    "        title = \"<s> \" + title + \" </s>\"\n",
    "        \n",
    "        print(\"Actual title: \", actual_title)\n",
    "        print(\"Predicted title: \", title)\n",
    "        \n",
    "        all_predicted_titles.append(title)\n",
    "        all_actual_titles.append(actual_title)\n",
    "        \n",
    "    return all_predicted_titles\n",
    "\n",
    "all_predicted_titles = generate_titles(model_two, X_test, y_test, tokenizer_titles, 0.6)\n",
    "all_predicted_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
